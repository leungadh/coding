{
  
    
        "post0": {
            "title": "Examining tabular datasets in fast.ai",
            "content": "!pip install -Uqq fastbook import fastbook from fastbook import * from fastai.vision.all import * . |████████████████████████████████| 720 kB 5.3 MB/s |████████████████████████████████| 1.2 MB 34.1 MB/s |████████████████████████████████| 189 kB 43.4 MB/s |████████████████████████████████| 48 kB 4.5 MB/s |████████████████████████████████| 55 kB 3.8 MB/s |████████████████████████████████| 561 kB 42.8 MB/s |████████████████████████████████| 51 kB 301 kB/s |████████████████████████████████| 130 kB 44.6 MB/s . fastbook.setup_book() . Mounted at /content/gdrive . path = untar_data(URLs.ADULT_SAMPLE) . . 100.69% [974848/968212 00:00&lt;00:00] path.ls() . (#3) [Path(&#39;/root/.fastai/data/adult_sample/export.pkl&#39;),Path(&#39;/root/.fastai/data/adult_sample/adult.csv&#39;),Path(&#39;/root/.fastai/data/adult_sample/models&#39;)] . df = pd.read_csv(path/&#39;adult.csv&#39;) . df.head() . age workclass fnlwgt education education-num marital-status occupation relationship race sex capital-gain capital-loss hours-per-week native-country salary . 0 49 | Private | 101320 | Assoc-acdm | 12.0 | Married-civ-spouse | NaN | Wife | White | Female | 0 | 1902 | 40 | United-States | &gt;=50k | . 1 44 | Private | 236746 | Masters | 14.0 | Divorced | Exec-managerial | Not-in-family | White | Male | 10520 | 0 | 45 | United-States | &gt;=50k | . 2 38 | Private | 96185 | HS-grad | NaN | Divorced | NaN | Unmarried | Black | Female | 0 | 0 | 32 | United-States | &lt;50k | . 3 38 | Self-emp-inc | 112847 | Prof-school | 15.0 | Married-civ-spouse | Prof-specialty | Husband | Asian-Pac-Islander | Male | 0 | 0 | 40 | United-States | &gt;=50k | . 4 42 | Self-emp-not-inc | 82297 | 7th-8th | NaN | Married-civ-spouse | Other-service | Wife | Black | Female | 0 | 0 | 50 | United-States | &lt;50k | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; df.shape . (32561, 15) . df.nunique() . age 73 workclass 9 fnlwgt 21648 education 16 education-num 16 marital-status 7 occupation 15 relationship 6 race 5 sex 2 capital-gain 119 capital-loss 92 hours-per-week 94 native-country 42 salary 2 dtype: int64 . df.isnull().sum() . age 0 workclass 0 fnlwgt 0 education 0 education-num 487 marital-status 0 occupation 512 relationship 0 race 0 sex 0 capital-gain 0 capital-loss 0 hours-per-week 0 native-country 0 salary 0 dtype: int64 . # streetcarjan2014[streetcarjan2014.Location == &quot;King and Shaw&quot;].Route df_young = df[df.age &lt;= 40] df_young.head() . age workclass fnlwgt education education-num marital-status occupation relationship race sex capital-gain capital-loss hours-per-week native-country salary . 2 38 | Private | 96185 | HS-grad | NaN | Divorced | NaN | Unmarried | Black | Female | 0 | 0 | 32 | United-States | &lt;50k | . 3 38 | Self-emp-inc | 112847 | Prof-school | 15.0 | Married-civ-spouse | Prof-specialty | Husband | Asian-Pac-Islander | Male | 0 | 0 | 40 | United-States | &gt;=50k | . 5 20 | Private | 63210 | HS-grad | 9.0 | Never-married | Handlers-cleaners | Own-child | White | Male | 0 | 0 | 15 | United-States | &lt;50k | . 7 37 | Private | 138940 | 11th | 7.0 | Married-civ-spouse | NaN | Husband | White | Male | 0 | 0 | 40 | United-States | &lt;50k | . 9 36 | Self-emp-inc | 216711 | HS-grad | NaN | Married-civ-spouse | NaN | Husband | White | Male | 99999 | 0 | 50 | ? | &gt;=50k | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt;",
            "url": "https://leungadh.github.io/coding/fastai/cookbook/2022/03/29/_23-examining_tabular_datasets.html",
            "relUrl": "/fastai/cookbook/2022/03/29/_23-examining_tabular_datasets.html",
            "date": " • Mar 29, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "FastAi program 1",
            "content": "!pip install -Uqq fastbook . |████████████████████████████████| 720 kB 5.7 MB/s |████████████████████████████████| 1.2 MB 38.3 MB/s |████████████████████████████████| 49 kB 5.3 MB/s |████████████████████████████████| 187 kB 45.3 MB/s |████████████████████████████████| 56 kB 4.1 MB/s |████████████████████████████████| 51 kB 299 kB/s |████████████████████████████████| 561 kB 44.0 MB/s |████████████████████████████████| 130 kB 45.2 MB/s . import fastbook from fastbook import * from fastai.vision.all import * . Download Image of Pets and Dogs . path = untar_data(URLs.PETS)/&#39;images&#39; . . 100.00% [811712512/811706944 00:15&lt;00:00] Define the Y-value of samples from file name. . def is_cat(x): return x[0].isupper() . Use the class ImageDataLoader to separate Dogs and Cats . dls = ImageDataLoaders.from_name_func( path, get_image_files(path), valid_pct=0.2, seed=42, label_func=is_cat, item_tfms=Resize(224)) . Then we can start the training. . learn = cnn_learner(dls, resnet34, metrics=error_rate) learn.fine_tune(10) . Downloading: &#34;https://download.pytorch.org/models/resnet34-b627a593.pth&#34; to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth . epoch train_loss valid_loss error_rate time . 0 | 0.176983 | 0.025701 | 0.008119 | 01:40 | . epoch train_loss valid_loss error_rate time . 0 | 0.044774 | 0.015274 | 0.005413 | 02:17 | . 1 | 0.051577 | 0.028491 | 0.008796 | 02:17 | . 2 | 0.028409 | 0.022383 | 0.006766 | 02:17 | . 3 | 0.023938 | 0.019018 | 0.006766 | 02:17 | . 4 | 0.023373 | 0.012015 | 0.006089 | 02:17 | . 5 | 0.011624 | 0.011480 | 0.003383 | 02:17 | . 6 | 0.007147 | 0.010880 | 0.002706 | 02:17 | . 7 | 0.003290 | 0.005658 | 0.003383 | 02:17 | . 8 | 0.001731 | 0.006262 | 0.002706 | 02:18 | . 9 | 0.001556 | 0.006831 | 0.003383 | 02:17 | . path.ls() . (#7393) [Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/japanese_chin_39.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/pug_57.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/english_cocker_spaniel_176.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/basset_hound_32.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/newfoundland_170.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/samoyed_16.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/pug_155.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/Birman_92.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/german_shorthaired_197.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/Sphynx_153.jpg&#39;)...] . btn_upload = widgets.FileUpload() . btn_upload . img = PILImage.create(btn_upload.data[0]) img . is_cat,_,probs = learn.predict(img) print(f&quot;Is this a cat?: {is_cat}.&quot;) print(f&quot;Probability it&#39;s a cat: {probs[1].item():.6f}&quot;) . Is this a cat?: True. Probability it&#39;s a cat: 1.000000 .",
            "url": "https://leungadh.github.io/coding/vision/pets/classification/2022/03/29/_03_29_A1-pets-classification.html",
            "relUrl": "/vision/pets/classification/2022/03/29/_03_29_A1-pets-classification.html",
            "date": " • Mar 29, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Lesson 1 - What's your pet",
            "content": "Welcome to lesson 1! For those of you who are using a Jupyter Notebook for the first time, you can learn about this useful tool in a tutorial we prepared specially for you; click File-&gt;Open now and click 00_notebook_tutorial.ipynb. . In this lesson we will build our first image classifier from scratch, and see if we can achieve world-class results. Let&#39;s dive in! . Every notebook starts with the following line; it ensures that any charts or images displayed are shown in this notebook. . %matplotlib inline . We import all the necessary packages. We are going to work with the fastai V2 library which sits on top of Pytorch 1.3. The fastai library provides many useful functions that enable us to quickly and easily build neural networks and train our models. For now fastai v2 is in a separate package called fastai, butonce it&#39;s fully ready to be released, it will just be called fastai. . !pip install -Uqq fastbook import fastbook from fastbook import * from fastai.vision.all import * . |████████████████████████████████| 720 kB 8.9 MB/s |████████████████████████████████| 187 kB 71.0 MB/s |████████████████████████████████| 1.2 MB 57.1 MB/s |████████████████████████████████| 49 kB 6.9 MB/s |████████████████████████████████| 55 kB 5.0 MB/s |████████████████████████████████| 561 kB 64.7 MB/s |████████████████████████████████| 51 kB 422 kB/s |████████████████████████████████| 130 kB 66.9 MB/s . from fastai.vision.all import * from nbdev.showdoc import * set_seed(2) . If you&#39;re using a computer with an unusually small GPU, you may get an out of memory error when running this notebook. If this happens, click Kernel-&gt;Restart, uncomment the 2nd line below to use a smaller batch size (you&#39;ll learn all about what this means during the course), and try again. . bs = 64 # bs = 16 # uncomment this line if you run out of memory even after clicking Kernel-&gt;Restart . Looking at the data . We are going to use the Oxford-IIIT Pet Dataset by O. M. Parkhi et al., 2012 which features 12 cat breeds and 25 dogs breeds. Our model will need to learn to differentiate between these 37 distinct categories. According to their paper, the best accuracy they could get in 2012 was 59.21%, using a complex model that was specific to pet detection, with separate &quot;Image&quot;, &quot;Head&quot;, and &quot;Body&quot; models for the pet photos. Let&#39;s see how accurate we can be using deep learning! . We are going to use the untar_data function to which we must pass a URL as an argument and which will download and extract the data. . help(untar_data) . Help on function untar_data in module fastai.data.external: untar_data(url, archive=None, data=None, c_key=&#39;data&#39;, force_download=False) Download `url` to `fname` if `dest` doesn&#39;t exist, and extract to folder `dest` . path = untar_data(URLs.PETS); path . . 100.00% [811712512/811706944 00:17&lt;00:00] Path(&#39;/root/.fastai/data/oxford-iiit-pet&#39;) . Path.BASE_PATH = path # display all paths relative to dataset root path.ls() . (#2) [Path(&#39;annotations&#39;),Path(&#39;images&#39;)] . path_anno = path/&#39;annotations&#39; path_img = path/&#39;images&#39; . The first thing we do when we approach a problem is to take a look at the data. We always need to understand very well what the problem is and what the data looks like before we can figure out how to solve it. Taking a look at the data means understanding how the data directories are structured, what the labels are and what some sample images look like. . The main difference between the handling of image classification datasets is the way labels are stored. In this particular dataset, labels are stored in the filenames themselves. We will need to extract them to be able to classify the images into the correct categories. Fortunately, the fastai library has a handy function made exactly for this, ImageDataLoaders.from_path_re gets the labels from the filenames using a regular expression. . fnames = get_image_files(path_img) fnames . (#7390) [Path(&#39;images/japanese_chin_100.jpg&#39;),Path(&#39;images/boxer_46.jpg&#39;),Path(&#39;images/german_shorthaired_20.jpg&#39;),Path(&#39;images/keeshond_112.jpg&#39;),Path(&#39;images/newfoundland_172.jpg&#39;),Path(&#39;images/beagle_82.jpg&#39;),Path(&#39;images/Siamese_6.jpg&#39;),Path(&#39;images/Sphynx_233.jpg&#39;),Path(&#39;images/miniature_pinscher_13.jpg&#39;),Path(&#39;images/american_pit_bull_terrier_47.jpg&#39;)...] . dls = ImageDataLoaders.from_name_re( path, fnames, pat=r&#39;(.+)_ d+.jpg$&#39;, item_tfms=Resize(460), bs=bs, batch_tfms=[*aug_transforms(size=224, min_scale=0.75), Normalize.from_stats(*imagenet_stats)]) . dls.show_batch(max_n=9, figsize=(7,6)) . print(dls.vocab) len(dls.vocab),dls.c . [&#39;Abyssinian&#39;, &#39;Bengal&#39;, &#39;Birman&#39;, &#39;Bombay&#39;, &#39;British_Shorthair&#39;, &#39;Egyptian_Mau&#39;, &#39;Maine_Coon&#39;, &#39;Persian&#39;, &#39;Ragdoll&#39;, &#39;Russian_Blue&#39;, &#39;Siamese&#39;, &#39;Sphynx&#39;, &#39;american_bulldog&#39;, &#39;american_pit_bull_terrier&#39;, &#39;basset_hound&#39;, &#39;beagle&#39;, &#39;boxer&#39;, &#39;chihuahua&#39;, &#39;english_cocker_spaniel&#39;, &#39;english_setter&#39;, &#39;german_shorthaired&#39;, &#39;great_pyrenees&#39;, &#39;havanese&#39;, &#39;japanese_chin&#39;, &#39;keeshond&#39;, &#39;leonberger&#39;, &#39;miniature_pinscher&#39;, &#39;newfoundland&#39;, &#39;pomeranian&#39;, &#39;pug&#39;, &#39;saint_bernard&#39;, &#39;samoyed&#39;, &#39;scottish_terrier&#39;, &#39;shiba_inu&#39;, &#39;staffordshire_bull_terrier&#39;, &#39;wheaten_terrier&#39;, &#39;yorkshire_terrier&#39;] . (37, 37) . Training: resnet34 . Now we will start training our model. We will use a convolutional neural network backbone and a fully connected head with a single hidden layer as a classifier. Don&#39;t know what these things mean? Not to worry, we will dive deeper in the coming lessons. For the moment you need to know that we are building a model which will take images as input and will output the predicted probability for each of the categories (in this case, it will have 37 outputs). . We will train for 4 epochs (4 cycles through all our data). . learn = cnn_learner(dls, resnet34, metrics=error_rate).to_fp16() . Downloading: &#34;https://download.pytorch.org/models/resnet34-b627a593.pth&#34; to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth . learn.model . Sequential( (0): Sequential( (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU(inplace=True) (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False) (4): Sequential( (0): BasicBlock( (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (1): BasicBlock( (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (2): BasicBlock( (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (5): Sequential( (0): BasicBlock( (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (downsample): Sequential( (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): BasicBlock( (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (2): BasicBlock( (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (3): BasicBlock( (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (6): Sequential( (0): BasicBlock( (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (downsample): Sequential( (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (2): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (3): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (4): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (5): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (7): Sequential( (0): BasicBlock( (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (downsample): Sequential( (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): BasicBlock( (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (2): BasicBlock( (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) ) (1): Sequential( (0): AdaptiveConcatPool2d( (ap): AdaptiveAvgPool2d(output_size=1) (mp): AdaptiveMaxPool2d(output_size=1) ) (1): Flatten(full=False) (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (3): Dropout(p=0.25, inplace=False) (4): Linear(in_features=1024, out_features=512, bias=False) (5): ReLU(inplace=True) (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (7): Dropout(p=0.5, inplace=False) (8): Linear(in_features=512, out_features=37, bias=False) ) ) . learn.fit_one_cycle(4) . epoch train_loss valid_loss error_rate time . 0 | 2.017956 | 0.344515 | 0.110961 | 01:12 | . 1 | 0.719299 | 0.245050 | 0.083221 | 01:09 | . 2 | 0.408040 | 0.222778 | 0.076455 | 01:08 | . 3 | 0.320944 | 0.208005 | 0.066306 | 01:07 | . learn.save(&#39;stage-1&#39;) . Path(&#39;models/stage-1.pth&#39;) . Results . Let&#39;s see what results we have got. . We will first see which were the categories that the model most confused with one another. We will try to see if what the model predicted was reasonable or not. In this case the mistakes look reasonable (none of the mistakes seems obviously naive). This is an indicator that our classifier is working correctly. . Furthermore, when we plot the confusion matrix, we can see that the distribution is heavily skewed: the model makes the same mistakes over and over again but it rarely confuses other categories. This suggests that it just finds it difficult to distinguish some specific categories between each other; this is normal behaviour. . interp = ClassificationInterpretation.from_learner(learn) losses,idxs = interp.top_losses() len(dls.valid_ds)==len(losses)==len(idxs) . True . interp.plot_top_losses(9, figsize=(15,11)) . doc(interp.plot_top_losses) . Exception Traceback (most recent call last) &lt;ipython-input-20-a7fe6964f6f7&gt; in &lt;module&gt;() -&gt; 1 doc(interp.plot_top_losses) /usr/local/lib/python3.7/dist-packages/nbdev/showdoc.py in doc(elt, show_all_docments) 441 def doc(elt:int, show_all_docments:bool=True): 442 &#34;Show `show_doc` info in preview window when used in a notebook&#34; --&gt; 443 md = show_doc(elt, disp=False, show_all_docments=show_all_docments) 444 doc_link = get_doc_link(elt) 445 if doc_link is not None: /usr/local/lib/python3.7/dist-packages/nbdev/showdoc.py in show_doc(elt, doc_string, name, title_level, disp, default_cls_level, show_all_docments, verbose) 386 s = &#39;&#39; 387 try: --&gt; 388 monospace = get_config().d.getboolean(&#39;monospace_docstrings&#39;, False) 389 except FileNotFoundError: 390 monospace = False /usr/local/lib/python3.7/dist-packages/nbdev/imports.py in get_config(cfg_name) 27 cfg_path = Path.cwd() 28 while cfg_path != cfg_path.parent and not (cfg_path/cfg_name).exists(): cfg_path = cfg_path.parent &gt; 29 config = Config(cfg_path, cfg_name=cfg_name) 30 _add_new_defaults(config.d, config.config_file, 31 host=&#34;github&#34;, doc_host=&#34;https://%(user)s.github.io&#34;, doc_baseurl=&#34;/%(lib_name)s/&#34;) /usr/local/lib/python3.7/dist-packages/fastcore/foundation.py in __init__(self, cfg_path, cfg_name, create) 258 cfg_path.mkdir(exist_ok=True, parents=True) 259 self.save() --&gt; 260 else: raise Exception(f&#34;Could not find {cfg_name}&#34;) 261 self.d = read_config_file(self.config_file) 262 Exception: Could not find settings.ini . interp.plot_top_losses . interp.plot_confusion_matrix(figsize=(12,12), dpi=60) . interp.most_confused(min_val=2) . [(&#39;Ragdoll&#39;, &#39;Birman&#39;, 7), (&#39;staffordshire_bull_terrier&#39;, &#39;american_pit_bull_terrier&#39;, 6), (&#39;Siamese&#39;, &#39;Birman&#39;, 5), (&#39;Bengal&#39;, &#39;Egyptian_Mau&#39;, 4), (&#39;american_bulldog&#39;, &#39;american_pit_bull_terrier&#39;, 4), (&#39;Russian_Blue&#39;, &#39;British_Shorthair&#39;, 3), (&#39;american_pit_bull_terrier&#39;, &#39;staffordshire_bull_terrier&#39;, 3), (&#39;boxer&#39;, &#39;american_bulldog&#39;, 3), (&#39;Birman&#39;, &#39;Ragdoll&#39;, 2), (&#39;Birman&#39;, &#39;Siamese&#39;, 2), (&#39;British_Shorthair&#39;, &#39;Bombay&#39;, 2), (&#39;Egyptian_Mau&#39;, &#39;Bengal&#39;, 2), (&#39;Maine_Coon&#39;, &#39;Ragdoll&#39;, 2), (&#39;american_pit_bull_terrier&#39;, &#39;miniature_pinscher&#39;, 2), (&#39;basset_hound&#39;, &#39;beagle&#39;, 2), (&#39;beagle&#39;, &#39;basset_hound&#39;, 2), (&#39;english_cocker_spaniel&#39;, &#39;english_setter&#39;, 2), (&#39;miniature_pinscher&#39;, &#39;chihuahua&#39;, 2)] . Unfreezing, fine-tuning, and learning rates . Since our model is working as we expect it to, we will unfreeze our model and train some more. . learn.unfreeze() . learn.fit_one_cycle(1) . epoch train_loss valid_loss error_rate time . 0 | 1.210634 | 0.606723 | 0.192152 | 01:18 | . learn.load(&#39;stage-1&#39;); . learn.lr_find() . SuggestedLRs(valley=2.75422871709452e-06) . learn.unfreeze() learn.fit_one_cycle(2, lr_max=slice(1e-6,1e-4)) . epoch train_loss valid_loss error_rate time . 0 | 0.309540 | 0.205545 | 0.068336 | 01:21 | . 1 | 0.288848 | 0.204862 | 0.068336 | 01:10 | . That&#39;s a pretty accurate model! . Training: resnet50 . Now we will train in the same way as before but with one caveat: instead of using resnet34 as our backbone we will use resnet50 (resnet34 is a 34 layer residual network while resnet50 has 50 layers. It will be explained later in the course and you can learn the details in the resnet paper). . Basically, resnet50 usually performs better because it is a deeper network with more parameters. Let&#39;s see if we can achieve a higher performance here. To help it along, let&#39;s us use larger images too, since that way the network can see more detail. We reduce the batch size a bit since otherwise this larger network will require more GPU memory. . dls = ImageDataLoaders.from_path_re(path_img, fnames, pat=r&#39;(.+)_ d+.jpg$&#39;, item_tfms=RandomResizedCrop(460, min_scale=0.75), bs=bs//2, batch_tfms=[*aug_transforms(size=299, max_warp=0), Normalize.from_stats(*imagenet_stats)]) . learn = cnn_learner(dls, resnet50, metrics=error_rate).to_fp16() . learn.lr_find() . learn.fit_one_cycle(8) . epoch train_loss valid_loss error_rate time . 0 | 0.703013 | 0.334534 | 0.108254 | 00:36 | . 1 | 0.501983 | 0.266966 | 0.083221 | 00:32 | . 2 | 0.380806 | 0.224438 | 0.077808 | 00:33 | . 3 | 0.314841 | 0.218427 | 0.069689 | 00:33 | . 4 | 0.200692 | 0.169219 | 0.055480 | 00:33 | . 5 | 0.157845 | 0.174981 | 0.061570 | 00:33 | . 6 | 0.109674 | 0.167735 | 0.053451 | 00:33 | . 7 | 0.082896 | 0.155995 | 0.052774 | 00:33 | . learn.save(&#39;stage-1-50&#39;) . It&#39;s astonishing that it&#39;s possible to recognize pet breeds so accurately! Let&#39;s see if full fine-tuning helps: . learn.unfreeze() learn.fit_one_cycle(3, lr_max=slice(1e-6,1e-4)) . epoch train_loss valid_loss error_rate time . 0 | 0.100100 | 0.157864 | 0.049391 | 00:42 | . 1 | 0.077801 | 0.162337 | 0.052097 | 00:41 | . 2 | 0.060328 | 0.153298 | 0.050744 | 00:41 | . If it doesn&#39;t, you can always go back to your previous model. . learn.load(&#39;stage-1-50&#39;); . interp = ClassificationInterpretation.from_learner(learn) . interp.most_confused(min_val=2) . [(&#39;Ragdoll&#39;, &#39;Birman&#39;, 8), (&#39;Egyptian_Mau&#39;, &#39;Bengal&#39;, 3), (&#39;american_pit_bull_terrier&#39;, &#39;staffordshire_bull_terrier&#39;, 3), (&#39;staffordshire_bull_terrier&#39;, &#39;american_bulldog&#39;, 3), (&#39;Birman&#39;, &#39;Ragdoll&#39;, 2), (&#39;Birman&#39;, &#39;Siamese&#39;, 2), (&#39;British_Shorthair&#39;, &#39;Russian_Blue&#39;, 2), (&#39;Egyptian_Mau&#39;, &#39;Bombay&#39;, 2), (&#39;Sphynx&#39;, &#39;Abyssinian&#39;, 2), (&#39;american_pit_bull_terrier&#39;, &#39;american_bulldog&#39;, 2), (&#39;beagle&#39;, &#39;basset_hound&#39;, 2), (&#39;chihuahua&#39;, &#39;miniature_pinscher&#39;, 2), (&#39;english_cocker_spaniel&#39;, &#39;german_shorthaired&#39;, 2), (&#39;miniature_pinscher&#39;, &#39;american_pit_bull_terrier&#39;, 2), (&#39;staffordshire_bull_terrier&#39;, &#39;american_pit_bull_terrier&#39;, 2)] . Other data formats . path = untar_data(URLs.MNIST_SAMPLE); path . PosixPath(&#39;/home/sgugger/.fastai/data/mnist_sample&#39;) . tfms = aug_transforms(do_flip=False) data = ImageDataLoaders.from_folder(path, batch_tfms=tfms, size=26, bs=bs) . data.show_batch(max_n=9, figsize=(5,6)) . learn = cnn_learner(data, resnet18, metrics=accuracy) learn.fit(2) . epoch train_loss valid_loss accuracy time . 0 | 0.199642 | 0.187065 | 0.939156 | 00:18 | . 1 | 0.116144 | 0.110818 | 0.962709 | 00:17 | . df = pd.read_csv(path/&#39;labels.csv&#39;) df.head() . name label . 0 train/3/7463.png | 0 | . 1 train/3/21102.png | 0 | . 2 train/3/31559.png | 0 | . 3 train/3/46882.png | 0 | . 4 train/3/26209.png | 0 | . data = ImageDataLoaders.from_csv(path, batch_tfms=tfms, size=28) . data.show_batch(max_n=9, figsize=(5,6)) data.vocab . (#2) [0,1] . data = ImageDataLoaders.from_df(df, path=path, batch_tfms=tfms, size=24) data.vocab . (#2) [0,1] . fn_paths = [path/name for name in df[&#39;name&#39;]]; fn_paths[:2] . [PosixPath(&#39;/home/sgugger/.fastai/data/mnist_sample/train/3/7463.png&#39;), PosixPath(&#39;/home/sgugger/.fastai/data/mnist_sample/train/3/21102.png&#39;)] . pat = r&quot;/( d)/ d+ .png$&quot; data = ImageDataLoaders.from_path_re(path, fn_paths, pat=pat, batch_tfms=tfms, size=24) data.vocab . (#2) [3,7] . data = ImageDataLoaders.from_path_func(path, fn_paths, batch_tfms=tfms, size=24, label_func = lambda x: &#39;3&#39; if &#39;/3/&#39; in str(x) else &#39;7&#39;) data.vocab . (#2) [3,7] . labels = [(&#39;3&#39; if &#39;/3/&#39; in str(x) else &#39;7&#39;) for x in fn_paths] labels[:5] . [&#39;3&#39;, &#39;3&#39;, &#39;3&#39;, &#39;3&#39;, &#39;3&#39;] . data = ImageDataLoaders.from_lists(path, fn_paths, labels=labels, batch_tfms=tfms, size=24) data.vocab . (#2) [3,7] .",
            "url": "https://leungadh.github.io/coding/2022/03/29/_03_27-walk-1-pets.html",
            "relUrl": "/2022/03/29/_03_27-walk-1-pets.html",
            "date": " • Mar 29, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "FastAI Cookbook Ch.3.1. Training a model with tabular datasets in fast.ai",
            "content": "Prepare the notebook and ingest the dataset . The first section of this notebook is identical to the chapter 2 notebook for examining tabular curated datasets: https://github.com/PacktPublishing/Deep-Learning-with-fastai-Cookbook/blob/main/ch2/examining_tabular_datasets.ipynb . !pip install -Uqq fastbook import fastbook from fastbook import * from fastai.tabular.all import * . |████████████████████████████████| 720 kB 5.2 MB/s |████████████████████████████████| 1.2 MB 35.8 MB/s |████████████████████████████████| 48 kB 4.4 MB/s |████████████████████████████████| 189 kB 44.6 MB/s |████████████████████████████████| 55 kB 3.5 MB/s |████████████████████████████████| 51 kB 303 kB/s |████████████████████████████████| 561 kB 38.6 MB/s |████████████████████████████████| 130 kB 45.8 MB/s . fastbook.setup_book() . Mounted at /content/gdrive . path = untar_data(URLs.ADULT_SAMPLE) . . 100.69% [974848/968212 00:00&lt;00:00] path.ls() . (#3) [Path(&#39;/root/.fastai/data/adult_sample/export.pkl&#39;),Path(&#39;/root/.fastai/data/adult_sample/adult.csv&#39;),Path(&#39;/root/.fastai/data/adult_sample/models&#39;)] . df = pd.read_csv(path/&#39;adult.csv&#39;) . df.head() . age workclass fnlwgt education education-num marital-status occupation relationship race sex capital-gain capital-loss hours-per-week native-country salary . 0 49 | Private | 101320 | Assoc-acdm | 12.0 | Married-civ-spouse | NaN | Wife | White | Female | 0 | 1902 | 40 | United-States | &gt;=50k | . 1 44 | Private | 236746 | Masters | 14.0 | Divorced | Exec-managerial | Not-in-family | White | Male | 10520 | 0 | 45 | United-States | &gt;=50k | . 2 38 | Private | 96185 | HS-grad | NaN | Divorced | NaN | Unmarried | Black | Female | 0 | 0 | 32 | United-States | &lt;50k | . 3 38 | Self-emp-inc | 112847 | Prof-school | 15.0 | Married-civ-spouse | Prof-specialty | Husband | Asian-Pac-Islander | Male | 0 | 0 | 40 | United-States | &gt;=50k | . 4 42 | Self-emp-not-inc | 82297 | 7th-8th | NaN | Married-civ-spouse | Other-service | Wife | Black | Female | 0 | 0 | 50 | United-States | &lt;50k | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; df.shape . (32561, 15) . df.nunique() . age 73 workclass 9 fnlwgt 21648 education 16 education-num 16 marital-status 7 occupation 15 relationship 6 race 5 sex 2 capital-gain 119 capital-loss 92 hours-per-week 94 native-country 42 salary 2 dtype: int64 . df.isnull().sum() . age 0 workclass 0 fnlwgt 0 education 0 education-num 487 marital-status 0 occupation 512 relationship 0 race 0 sex 0 capital-gain 0 capital-loss 0 hours-per-week 0 native-country 0 salary 0 dtype: int64 . # streetcarjan2014[streetcarjan2014.Location == &quot;King and Shaw&quot;].Route df_young = df[df.age &lt;= 40] df_young.head() . age workclass fnlwgt education education-num marital-status occupation relationship race sex capital-gain capital-loss hours-per-week native-country salary . 2 38 | Private | 96185 | HS-grad | NaN | Divorced | NaN | Unmarried | Black | Female | 0 | 0 | 32 | United-States | &lt;50k | . 3 38 | Self-emp-inc | 112847 | Prof-school | 15.0 | Married-civ-spouse | Prof-specialty | Husband | Asian-Pac-Islander | Male | 0 | 0 | 40 | United-States | &gt;=50k | . 5 20 | Private | 63210 | HS-grad | 9.0 | Never-married | Handlers-cleaners | Own-child | White | Male | 0 | 0 | 15 | United-States | &lt;50k | . 7 37 | Private | 138940 | 11th | 7.0 | Married-civ-spouse | NaN | Husband | White | Male | 0 | 0 | 40 | United-States | &lt;50k | . 9 36 | Self-emp-inc | 216711 | HS-grad | NaN | Married-civ-spouse | NaN | Husband | White | Male | 99999 | 0 | 50 | ? | &gt;=50k | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Define transforms, dependent variable, continuous and categorical columns . In this section we defined the transforms that will be applied to the dataset along with the target, continuous and categorical columns . procs = [FillMissing,Categorify] # define the dependent variable (y value) dep_var = &#39;salary&#39; # define columns that are continuous / categorical cont,cat = cont_cat_split(df, 1, dep_var=dep_var) . cont . [&#39;age&#39;, &#39;fnlwgt&#39;, &#39;education-num&#39;, &#39;capital-gain&#39;, &#39;capital-loss&#39;, &#39;hours-per-week&#39;] . cat . [&#39;workclass&#39;, &#39;education&#39;, &#39;marital-status&#39;, &#39;occupation&#39;, &#39;relationship&#39;, &#39;race&#39;, &#39;sex&#39;, &#39;native-country&#39;] . Define TabularDataLoaders object . # valid_idx: the indices to use for the validation set dls=TabularDataLoaders.from_df(df,path,procs= procs, cat_names= cat, cont_names = cont, y_names = dep_var, valid_idx=list(range(1024,1260)), bs=64) . dls.show_batch() . workclass education marital-status occupation relationship race sex native-country education-num_na age fnlwgt education-num capital-gain capital-loss hours-per-week salary . 0 Private | HS-grad | Never-married | Handlers-cleaners | Own-child | White | Male | Portugal | False | 22.0 | 162667.0 | 9.0 | 0.0 | 0.0 | 50.0 | &lt;50k | . 1 Local-gov | HS-grad | Divorced | Protective-serv | Unmarried | White | Female | United-States | False | 43.0 | 186995.0 | 9.0 | 0.0 | 0.0 | 40.0 | &lt;50k | . 2 Self-emp-not-inc | Some-college | Never-married | Craft-repair | Not-in-family | White | Female | United-States | False | 18.0 | 42857.0 | 10.0 | 0.0 | 0.0 | 35.0 | &lt;50k | . 3 Private | HS-grad | Never-married | Other-service | Not-in-family | White | Male | United-States | False | 40.0 | 209040.0 | 9.0 | 0.0 | 0.0 | 40.0 | &lt;50k | . 4 Private | Bachelors | Divorced | Adm-clerical | Not-in-family | White | Female | United-States | False | 50.0 | 77905.0 | 13.0 | 0.0 | 0.0 | 8.0 | &lt;50k | . 5 ? | Prof-school | Married-civ-spouse | ? | Husband | White | Male | United-States | False | 63.0 | 247986.0 | 15.0 | 0.0 | 0.0 | 30.0 | &gt;=50k | . 6 Private | 12th | Never-married | Sales | Own-child | Black | Female | United-States | False | 18.0 | 311795.0 | 8.0 | 0.0 | 0.0 | 20.0 | &lt;50k | . 7 Local-gov | Masters | Married-civ-spouse | Prof-specialty | Husband | White | Male | United-States | False | 43.0 | 174395.0 | 14.0 | 0.0 | 0.0 | 50.0 | &lt;50k | . 8 Self-emp-inc | HS-grad | Never-married | Sales | Not-in-family | White | Male | United-States | False | 58.0 | 190541.0 | 9.0 | 0.0 | 0.0 | 47.0 | &lt;50k | . 9 Private | HS-grad | Married-civ-spouse | Other-service | Husband | White | Male | ? | False | 34.0 | 609789.0 | 9.0 | 0.0 | 0.0 | 30.0 | &lt;50k | . Define and train model . %%time learn = tabular_learner(dls,layers=[200,100], metrics=accuracy) learn.fit_one_cycle(3) . epoch train_loss valid_loss accuracy time . 0 | 0.341057 | 0.362043 | 0.817797 | 00:07 | . 1 | 0.327887 | 0.337167 | 0.843220 | 00:06 | . 2 | 0.305436 | 0.336424 | 0.847458 | 00:07 | . CPU times: user 22.7 s, sys: 1.37 s, total: 24.1 s Wall time: 31.1 s . learn.recorder.plot_loss() . learn.show_results() . workclass education marital-status occupation relationship race sex native-country education-num_na age fnlwgt education-num capital-gain capital-loss hours-per-week salary salary_pred . 0 7.0 | 12.0 | 3.0 | 13.0 | 1.0 | 5.0 | 2.0 | 40.0 | 1.0 | 58.0 | 248841.0 | 9.0 | 15024.0 | 0.0 | 40.0 | 1.0 | 1.0 | . 1 8.0 | 11.0 | 3.0 | 11.0 | 1.0 | 5.0 | 2.0 | 40.0 | 1.0 | 41.0 | 309056.0 | 16.0 | 0.0 | 0.0 | 50.0 | 1.0 | 1.0 | . 2 5.0 | 5.0 | 7.0 | 9.0 | 3.0 | 2.0 | 1.0 | 31.0 | 1.0 | 63.0 | 106910.0 | 3.0 | 0.0 | 0.0 | 19.0 | 0.0 | 0.0 | . 3 1.0 | 11.0 | 3.0 | 1.0 | 1.0 | 5.0 | 2.0 | 40.0 | 1.0 | 72.0 | 118902.0 | 16.0 | 0.0 | 2392.0 | 6.0 | 1.0 | 1.0 | . 4 5.0 | 2.0 | 5.0 | 7.0 | 3.0 | 3.0 | 1.0 | 40.0 | 1.0 | 41.0 | 155657.0 | 7.0 | 0.0 | 0.0 | 40.0 | 0.0 | 0.0 | . 5 5.0 | 2.0 | 1.0 | 8.0 | 2.0 | 5.0 | 2.0 | 40.0 | 1.0 | 38.0 | 252250.0 | 7.0 | 0.0 | 0.0 | 65.0 | 0.0 | 0.0 | . 6 5.0 | 16.0 | 5.0 | 15.0 | 5.0 | 5.0 | 2.0 | 40.0 | 1.0 | 29.0 | 277342.0 | 10.0 | 0.0 | 0.0 | 40.0 | 0.0 | 0.0 | . 7 5.0 | 12.0 | 3.0 | 7.0 | 1.0 | 5.0 | 2.0 | 40.0 | 1.0 | 25.0 | 218667.0 | 9.0 | 0.0 | 0.0 | 40.0 | 0.0 | 0.0 | . 8 7.0 | 10.0 | 1.0 | 5.0 | 2.0 | 5.0 | 2.0 | 40.0 | 1.0 | 54.0 | 154785.0 | 13.0 | 0.0 | 0.0 | 50.0 | 0.0 | 0.0 | . Examine the structure of the trained model structure . Use the summary() function to see the structure of the trained model, including: . the layers that make up the model | total parameters | loss function | optimizer function | callbacks | . learn.summary() . TabularModel (Input shape: 64 x 9) ============================================================================ Layer (type) Output Shape Param # Trainable ============================================================================ 64 x 6 Embedding 60 True ____________________________________________________________________________ 64 x 8 Embedding 136 True ____________________________________________________________________________ 64 x 5 Embedding 40 True ____________________________________________________________________________ 64 x 8 Embedding 128 True ____________________________________________________________________________ 64 x 5 Embedding 35 True ____________________________________________________________________________ 64 x 4 Embedding 24 True ____________________________________________________________________________ 64 x 3 Embedding 9 True ____________________________________________________________________________ 64 x 13 Embedding 559 True ____________________________________________________________________________ 64 x 3 Embedding 9 True Dropout BatchNorm1d 12 True ____________________________________________________________________________ 64 x 200 Linear 12200 True ReLU BatchNorm1d 400 True ____________________________________________________________________________ 64 x 100 Linear 20000 True ReLU BatchNorm1d 200 True ____________________________________________________________________________ 64 x 2 Linear 202 True ____________________________________________________________________________ Total params: 34,014 Total trainable params: 34,014 Total non-trainable params: 0 Optimizer used: &lt;function Adam at 0x7f9f1e50d320&gt; Loss function: FlattenedLoss of CrossEntropyLoss() Model unfrozen Callbacks: - TrainEvalCallback - Recorder - ProgressCallback . learn.model . TabularModel( (embeds): ModuleList( (0): Embedding(10, 6) (1): Embedding(17, 8) (2): Embedding(8, 5) (3): Embedding(16, 8) (4): Embedding(7, 5) (5): Embedding(6, 4) (6): Embedding(3, 3) (7): Embedding(43, 13) (8): Embedding(3, 3) ) (emb_drop): Dropout(p=0.0, inplace=False) (bn_cont): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (layers): Sequential( (0): LinBnDrop( (0): Linear(in_features=61, out_features=200, bias=False) (1): ReLU(inplace=True) (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (1): LinBnDrop( (0): Linear(in_features=200, out_features=100, bias=False) (1): ReLU(inplace=True) (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (2): LinBnDrop( (0): Linear(in_features=100, out_features=2, bias=True) ) ) ) .",
            "url": "https://leungadh.github.io/coding/fastai/cookbook/tabular/2022/03/29/_03_24-CB-training_with_tabular_datasets.html",
            "relUrl": "/fastai/cookbook/tabular/2022/03/29/_03_24-CB-training_with_tabular_datasets.html",
            "date": " • Mar 29, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "Using MNIST_Sample Model",
            "content": "!pip install -Uqq fastbook import fastbook from fastbook import * from fastai.vision.all import * . |████████████████████████████████| 720 kB 5.3 MB/s |████████████████████████████████| 48 kB 4.8 MB/s |████████████████████████████████| 189 kB 45.1 MB/s |████████████████████████████████| 1.2 MB 39.3 MB/s |████████████████████████████████| 55 kB 4.0 MB/s |████████████████████████████████| 561 kB 45.3 MB/s |████████████████████████████████| 51 kB 312 kB/s |████████████████████████████████| 130 kB 45.6 MB/s . fastbook.setup_book() . Mounted at /content/gdrive . path = untar_data(URLs.MNIST_SAMPLE) . . 100.14% [3219456/3214948 00:00&lt;00:00] path.ls() . (#3) [Path(&#39;/root/.fastai/data/mnist_sample/labels.csv&#39;),Path(&#39;/root/.fastai/data/mnist_sample/train&#39;),Path(&#39;/root/.fastai/data/mnist_sample/valid&#39;)] . %%time # create an image dataloaders object using the path # note that because of the directory structure of the dataset # the train and valid sets have to be explicitly specified # details here: https://github.com/fastai/fastai/issues/1129 dls = ImageDataLoaders.from_folder(path, train=&#39;train&#39;, valid=&#39;valid&#39;) # create a learner object using the dataloaders that was just defined # architecture is resnet18; see https://pytorch.org/hub/pytorch_vision_resnet/ # loss function is selected for multi class classification # accuracy is the metric used to optimize learn = cnn_learner(dls, resnet18, pretrained=False, loss_func=LabelSmoothingCrossEntropy(), metrics=accuracy) # fit the model for one epoch using 1cycle policy # see https://docs.fast.ai/callback.schedule.html#Learner.fit_one_cycle learn.fit_one_cycle(1, 0.1) . epoch train_loss valid_loss accuracy time . 0 | 0.308383 | 0.231135 | 0.989696 | 00:26 | . CPU times: user 19.1 s, sys: 1.74 s, total: 20.9 s Wall time: 38.4 s . dls.train.show_batch(max_n=4, nrows=1) . dls.valid.show_batch(max_n=4, nrows=1) . img_files = get_image_files(path/&quot;valid&quot;) len(img_files) . 2038 . path . Path(&#39;/root/.fastai/data/mnist_sample&#39;) . img_files = get_image_files(path/&quot;train&quot;) len(img_files) . 12396 . interp = ClassificationInterpretation.from_learner(learn) interp.plot_top_losses(4, nrows=1) . learn.summary() . Sequential (Input shape: 64 x 3 x 28 x 28) ============================================================================ Layer (type) Output Shape Param # Trainable ============================================================================ 64 x 64 x 14 x 14 Conv2d 9408 True BatchNorm2d 128 True ReLU ____________________________________________________________________________ 64 x 64 x 7 x 7 MaxPool2d Conv2d 36864 True BatchNorm2d 128 True ReLU Conv2d 36864 True BatchNorm2d 128 True Conv2d 36864 True BatchNorm2d 128 True ReLU Conv2d 36864 True BatchNorm2d 128 True ____________________________________________________________________________ 64 x 128 x 4 x 4 Conv2d 73728 True BatchNorm2d 256 True ReLU Conv2d 147456 True BatchNorm2d 256 True Conv2d 8192 True BatchNorm2d 256 True Conv2d 147456 True BatchNorm2d 256 True ReLU Conv2d 147456 True BatchNorm2d 256 True ____________________________________________________________________________ 64 x 256 x 2 x 2 Conv2d 294912 True BatchNorm2d 512 True ReLU Conv2d 589824 True BatchNorm2d 512 True Conv2d 32768 True BatchNorm2d 512 True Conv2d 589824 True BatchNorm2d 512 True ReLU Conv2d 589824 True BatchNorm2d 512 True ____________________________________________________________________________ 64 x 512 x 1 x 1 Conv2d 1179648 True BatchNorm2d 1024 True ReLU Conv2d 2359296 True BatchNorm2d 1024 True Conv2d 131072 True BatchNorm2d 1024 True Conv2d 2359296 True BatchNorm2d 1024 True ReLU Conv2d 2359296 True BatchNorm2d 1024 True AdaptiveAvgPool2d AdaptiveMaxPool2d ____________________________________________________________________________ 64 x 1024 Flatten BatchNorm1d 2048 True Dropout ____________________________________________________________________________ 64 x 512 Linear 524288 True ReLU BatchNorm1d 1024 True Dropout ____________________________________________________________________________ 64 x 2 Linear 1024 True ____________________________________________________________________________ Total params: 11,704,896 Total trainable params: 11,704,896 Total non-trainable params: 0 Optimizer used: &lt;function Adam at 0x7f9b89b999e0&gt; Loss function: LabelSmoothingCrossEntropy() Model unfrozen Callbacks: - TrainEvalCallback - Recorder - ProgressCallback . img = PILImage.create(img_files[0]) img . learn.predict(img) . (&#39;7&#39;, TensorBase(1), TensorBase([0.0566, 0.9434])) . img = PILImage.create(img_files[100]) img . learn.predict(img) . (&#39;7&#39;, TensorBase(1), TensorBase([0.0669, 0.9331])) . img = PILImage.create(img_files[1888]) img . learn.predict(img) . (&#39;3&#39;, TensorBase(0), TensorBase([0.9480, 0.0520])) .",
            "url": "https://leungadh.github.io/coding/fastai/cookbook/2022/03/29/_03_23_MNIST_Sample.html",
            "relUrl": "/fastai/cookbook/2022/03/29/_03_23_MNIST_Sample.html",
            "date": " • Mar 29, 2022"
        }
        
    
  
    
        ,"post5": {
            "title": "PyTorch tensor walkthrough",
            "content": "import torch . a = torch.ones(5, 7, dtype=torch.float) a . tensor([[1., 1., 1., 1., 1., 1., 1.], [1., 1., 1., 1., 1., 1., 1.], [1., 1., 1., 1., 1., 1., 1.], [1., 1., 1., 1., 1., 1., 1.], [1., 1., 1., 1., 1., 1., 1.]]) . b = torch.eye(5,7) b . tensor([[1., 0., 0., 0., 0., 0., 0.], [0., 1., 0., 0., 0., 0., 0.], [0., 0., 1., 0., 0., 0., 0.], [0., 0., 0., 1., 0., 0., 0.], [0., 0., 0., 0., 1., 0., 0.]]) . c = torch.eye(5,5) c . tensor([[1., 0., 0., 0., 0.], [0., 1., 0., 0., 0.], [0., 0., 1., 0., 0.], [0., 0., 0., 1., 0.], [0., 0., 0., 0., 1.]]) . Examine tensor elements . b[0] . tensor([1., 0., 0., 0., 0., 0., 0.]) . b[0,0] . tensor(1.) . b[2:] . tensor([[0., 0., 1., 0., 0., 0., 0.], [0., 0., 0., 1., 0., 0., 0.], [0., 0., 0., 0., 1., 0., 0.]]) . b[2:,2:] . tensor([[1., 0., 0., 0., 0.], [0., 1., 0., 0., 0.], [0., 0., 1., 0., 0.]]) . b[:2] . tensor([[1., 0., 0., 0., 0., 0., 0.], [0., 1., 0., 0., 0., 0., 0.]]) . Do operations on the tensors . a_plus_b = a + b a_plus_b . tensor([[2., 1., 1., 1., 1., 1., 1.], [1., 2., 1., 1., 1., 1., 1.], [1., 1., 2., 1., 1., 1., 1.], [1., 1., 1., 2., 1., 1., 1.], [1., 1., 1., 1., 2., 1., 1.]]) . a_mult_c = a@c a_mult_c . RuntimeError Traceback (most recent call last) &lt;ipython-input-16-95709c4f3868&gt; in &lt;module&gt;() 1 # multiply two tensors - this cell will produce an error -&gt; 2 a_mult_c = a@c 3 a_mult_c RuntimeError: mat1 and mat2 shapes cannot be multiplied (5x7 and 5x5) . d = torch.eye(7,7) d . tensor([[1., 0., 0., 0., 0., 0., 0.], [0., 1., 0., 0., 0., 0., 0.], [0., 0., 1., 0., 0., 0., 0.], [0., 0., 0., 1., 0., 0., 0.], [0., 0., 0., 0., 1., 0., 0.], [0., 0., 0., 0., 0., 1., 0.], [0., 0., 0., 0., 0., 0., 1.]]) . # (5 x 7) x (7 x 7) = (5, 7) a_mult_d = a@d a_mult_d . tensor([[1., 1., 1., 1., 1., 1., 1.], [1., 1., 1., 1., 1., 1., 1.], [1., 1., 1., 1., 1., 1., 1.], [1., 1., 1., 1., 1., 1., 1.], [1., 1., 1., 1., 1., 1., 1.]]) . # transpose swap the (1,0) position to (0,1) a_trans = torch.transpose(a,0,1) a_trans . tensor([[1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.]]) . a_trans_mult_c = a_trans @ c a_trans_mult_c . tensor([[1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.], [1., 1., 1., 1., 1.]]) . k = torch.rand(2,3) k . tensor([[0.2867, 0.3341, 0.9063], [0.8328, 0.4341, 0.3288]]) . # input (Tensor): the input tensor. # dim0 (int): the first dimension to be transposed # dim1 (int): the second dimension to be transposed k_transpose = torch.transpose(k,0,1) k_transpose . tensor([[0.2867, 0.8328], [0.3341, 0.4341], [0.9063, 0.3288]]) . y = torch.rand(3,5) y_transpose = torch.transpose(y,0,1) y y_transpose . tensor([[0.0667, 0.8654, 0.5013], [0.5284, 0.8657, 0.6256], [0.5109, 0.7786, 0.8958], [0.4998, 0.2655, 0.4263], [0.1802, 0.6168, 0.6323]]) . y . tensor([[0.0667, 0.5284, 0.5109, 0.4998, 0.1802], [0.8654, 0.8657, 0.7786, 0.2655, 0.6168], [0.5013, 0.6256, 0.8958, 0.4263, 0.6323]]) .",
            "url": "https://leungadh.github.io/coding/2022/03/29/_03_23-pytorch_tensor_walkthrough.html",
            "relUrl": "/2022/03/29/_03_23-pytorch_tensor_walkthrough.html",
            "date": " • Mar 29, 2022"
        }
        
    
  
    
        ,"post6": {
            "title": "Keras sequential API "hello world" model for MNIST",
            "content": "import tensorflow as tf import pydotplus from tensorflow.keras.utils import plot_model . mnist = tf.keras.datasets.mnist (x_train, y_train), (x_test, y_test) = mnist.load_data() x_train, x_test = x_train / 255.0, x_test / 255.0 . Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz 11493376/11490434 [==============================] - 0s 0us/step 11501568/11490434 [==============================] - 0s 0us/step . hello_world_model = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), tf.keras.layers.Dense(128, activation=&#39;relu&#39;), tf.keras.layers.Dropout(0.15), tf.keras.layers.Dense(10) ]) . hello_world_model.compile(optimizer=&#39;adam&#39;, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[&#39;accuracy&#39;]) # train model history = hello_world_model.fit(x_train, y_train, batch_size=64, epochs=10, validation_split=0.15) # assess performance of the model test_scores = hello_world_model.evaluate(x_test, y_test, verbose=2) print(&#39;Loss for test dataset:&#39;, test_scores[0]) print(&#39;Accuracy for test dataset:&#39;, test_scores[1]) . Epoch 1/10 797/797 [==============================] - 5s 3ms/step - loss: 0.3619 - accuracy: 0.8978 - val_loss: 0.1691 - val_accuracy: 0.9530 Epoch 2/10 797/797 [==============================] - 2s 3ms/step - loss: 0.1701 - accuracy: 0.9513 - val_loss: 0.1196 - val_accuracy: 0.9648 Epoch 3/10 797/797 [==============================] - 2s 3ms/step - loss: 0.1270 - accuracy: 0.9615 - val_loss: 0.0961 - val_accuracy: 0.9719 Epoch 4/10 797/797 [==============================] - 2s 3ms/step - loss: 0.1015 - accuracy: 0.9695 - val_loss: 0.0864 - val_accuracy: 0.9757 Epoch 5/10 797/797 [==============================] - 2s 3ms/step - loss: 0.0841 - accuracy: 0.9741 - val_loss: 0.0829 - val_accuracy: 0.9757 Epoch 6/10 797/797 [==============================] - 2s 3ms/step - loss: 0.0695 - accuracy: 0.9784 - val_loss: 0.0794 - val_accuracy: 0.9758 Epoch 7/10 797/797 [==============================] - 2s 3ms/step - loss: 0.0591 - accuracy: 0.9812 - val_loss: 0.0803 - val_accuracy: 0.9763 Epoch 8/10 797/797 [==============================] - 2s 3ms/step - loss: 0.0538 - accuracy: 0.9831 - val_loss: 0.0775 - val_accuracy: 0.9774 Epoch 9/10 797/797 [==============================] - 2s 3ms/step - loss: 0.0481 - accuracy: 0.9847 - val_loss: 0.0746 - val_accuracy: 0.9786 Epoch 10/10 797/797 [==============================] - 2s 3ms/step - loss: 0.0420 - accuracy: 0.9865 - val_loss: 0.0717 - val_accuracy: 0.9793 313/313 - 0s - loss: 0.0657 - accuracy: 0.9806 - 483ms/epoch - 2ms/step Loss for test dataset: 0.06568299978971481 Accuracy for test dataset: 0.9805999994277954 . test_scores = hello_world_model.evaluate(x_test, y_test, verbose=2) print(&#39;Loss for test dataset:&#39;, test_scores[0]) print(&#39;Accuracy for test dataset:&#39;, test_scores[1]) . 313/313 - 0s - loss: 0.0657 - accuracy: 0.9806 - 480ms/epoch - 2ms/step Loss for test dataset: 0.06568299978971481 Accuracy for test dataset: 0.9805999994277954 .",
            "url": "https://leungadh.github.io/coding/keras/tensorflow/2022/03/29/_03_23-keras_sequential_api_hello_world.html",
            "relUrl": "/keras/tensorflow/2022/03/29/_03_23-keras_sequential_api_hello_world.html",
            "date": " • Mar 29, 2022"
        }
        
    
  
    
        ,"post7": {
            "title": "Walkthrough of fast.ai Curated Datasets",
            "content": "!pip install -Uqq fastbook import fastbook from fastbook import * from fastai.vision.all import * . |████████████████████████████████| 720 kB 13.3 MB/s |████████████████████████████████| 48 kB 5.0 MB/s |████████████████████████████████| 1.2 MB 41.4 MB/s |████████████████████████████████| 189 kB 52.1 MB/s |████████████████████████████████| 55 kB 3.3 MB/s |████████████████████████████████| 561 kB 46.0 MB/s |████████████████████████████████| 51 kB 304 kB/s |████████████████████████████████| 130 kB 49.3 MB/s . fastbook.setup_book() . Mounted at /content/gdrive . path = untar_data(URLs.MNIST) . . 100.03% [15687680/15683414 00:01&lt;00:00] path.ls() . (#2) [Path(&#39;/root/.fastai/data/mnist_png/testing&#39;),Path(&#39;/root/.fastai/data/mnist_png/training&#39;)] . type(URLs.MNIST) . str . ??URLs . path.ls() . (#2) [Path(&#39;/storage/data/mnist_png/training&#39;),Path(&#39;/storage/data/mnist_png/testing&#39;)] . (path/&#39;training&#39;).ls() . (#10) [Path(&#39;/root/.fastai/data/mnist_png/training/6&#39;),Path(&#39;/root/.fastai/data/mnist_png/training/4&#39;),Path(&#39;/root/.fastai/data/mnist_png/training/0&#39;),Path(&#39;/root/.fastai/data/mnist_png/training/2&#39;),Path(&#39;/root/.fastai/data/mnist_png/training/8&#39;),Path(&#39;/root/.fastai/data/mnist_png/training/7&#39;),Path(&#39;/root/.fastai/data/mnist_png/training/5&#39;),Path(&#39;/root/.fastai/data/mnist_png/training/3&#39;),Path(&#39;/root/.fastai/data/mnist_png/training/1&#39;),Path(&#39;/root/.fastai/data/mnist_png/training/9&#39;)] . ??untar_data . path = untar_data(URLs.PETS) . . 100.00% [811712512/811706944 00:22&lt;00:00] path.ls() . (#2) [Path(&#39;/root/.fastai/data/oxford-iiit-pet/annotations&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images&#39;)] . (path/&#39;images&#39;).ls() . (#7393) [Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/Abyssinian_103.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/havanese_172.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/great_pyrenees_80.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/Bengal_61.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/german_shorthaired_56.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/beagle_202.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/pomeranian_142.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/miniature_pinscher_177.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/Persian_3.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-iiit-pet/images/great_pyrenees_10.jpg&#39;)...] . ??Path.ls . doc(Path.ls) . Path.ls[source] . Path.ls(n_max=None, file_type=None, file_exts=None) . Contents of path as a list . Type Default . n_max | NoneType | `` | . file_type | NoneType | `` | . file_exts | NoneType | `` | . Show in docs .",
            "url": "https://leungadh.github.io/coding/fastai/cookbook/2022/03/29/_03_23-fastai-data-walkthru.html",
            "relUrl": "/fastai/cookbook/2022/03/29/_03_23-fastai-data-walkthru.html",
            "date": " • Mar 29, 2022"
        }
        
    
  
    
        ,"post8": {
            "title": "FastAI Cookbook Ch2. Examining text datasets in fast.ai",
            "content": "!pip install -Uqq fastbook import fastbook from fastbook import * from fastai.text.all import * from fastai.vision.all import * . |████████████████████████████████| 720 kB 5.2 MB/s |████████████████████████████████| 48 kB 4.5 MB/s |████████████████████████████████| 189 kB 49.0 MB/s |████████████████████████████████| 1.2 MB 40.5 MB/s |████████████████████████████████| 55 kB 3.5 MB/s |████████████████████████████████| 51 kB 283 kB/s |████████████████████████████████| 561 kB 36.8 MB/s |████████████████████████████████| 130 kB 51.1 MB/s . fastbook.setup_book() . Mounted at /content/gdrive . path = untar_data(URLs.WIKITEXT_TINY) . . 100.03% [4071424/4070055 00:00&lt;00:00] path.ls() . (#2) [Path(&#39;/root/.fastai/data/wikitext-2/train.csv&#39;),Path(&#39;/root/.fastai/data/wikitext-2/test.csv&#39;)] . df_train = pd.read_csv(path/&#39;train.csv&#39;) df_train.head(2) . n = 2013 – 14 York City F.C. season = n n The 2013 – 14 season was the &lt;unk&gt; season of competitive association football and 77th season in the Football League played by York City Football Club , a professional football club based in York , North Yorkshire , England . Their 17th @-@ place finish in 2012 – 13 meant it was their second consecutive season in League Two . The season ran from 1 July 2013 to 30 June 2014 . n Nigel Worthington , starting his first full season as York manager , made eight permanent summer signings . By the turn of the year York were only above the relegation zone on goal difference , before a 17 @-@ match unbeaten run saw the team finish in seventh @-@ place in the 24 @-@ team 2013 – 14 Football League Two . This meant York qualified for the play @-@ offs , and they were eliminated in the semi @-@ final by Fleetwood Town . York were knocked out of the 2013 – 14 FA Cup , Football League Cup and Football League Trophy in their opening round matches . n 35 players made at least one appearance in nationally organised first @-@ team competition , and there were 12 different &lt;unk&gt; . Defender Ben Davies missed only five of the fifty @-@ two competitive matches played over the season . Wes Fletcher finished as leading scorer with 13 goals , of which 10 came in league competition and three came in the FA Cup . The winner of the &lt;unk&gt; of the Year award , voted for by the club &#39;s supporters , was &lt;unk&gt; Oyebanjo . n n = = Background and pre @-@ season = = n n The 2012 – 13 season was York City &#39;s first season back in the Football League , having won the Conference Premier play @-@ offs in 2011 – 12 after &lt;unk&gt; years in the Football Conference . Manager Gary Mills was sacked in March 2013 following an 11 @-@ match run without a victory , and was replaced by former Northern Ireland manager Nigel Worthington . Despite being in the relegation zone with three matches remaining , Worthington led the team to safety from relegation after a 1 – 0 win away to Dagenham &amp; Redbridge on the final day of the season . York finished the season in 17th @-@ place in the 2012 – 13 League Two table . n Following the previous season &#39;s conclusion Lee &lt;unk&gt; , Jon &lt;unk&gt; , Chris &lt;unk&gt; , Ben Everson , Scott Kerr , David &lt;unk&gt; , Patrick &lt;unk&gt; , Michael Potts , Jamie Reed and Jason Walker were released by York , while &lt;unk&gt; Blair departed for Fleetwood Town . David McGurk , &lt;unk&gt; Oyebanjo , Danny Parslow , Tom Platt and Chris Smith signed new contracts with the club . New players signed ahead of the start of the season were goalkeeper Chris &lt;unk&gt; on a season @-@ long loan from Blackpool , defender Ben Davies on loan from Preston North End , midfielders Craig Clay from Chesterfield and Lewis Montrose from Gillingham , winger &lt;unk&gt; Puri from St &lt;unk&gt; and strikers Ryan Bowman from Hereford United , Richard Cresswell from Sheffield United , Wes Fletcher from Burnley and Ryan Jarvis from Torquay United . Defender Mike Atkinson and striker Chris Dickinson entered the first @-@ team squad from the youth team after agreeing professional contracts . n York retained the previous season &#39;s home and away kits . The home kit comprised red shirts with white sleeves , light blue shorts and white socks . The away kit included light blue shirts with white sleeves , white shorts and light blue socks . &lt;unk&gt; Health continued as shirt sponsors for the second successive season . n n = = Review = = n n n = = = August = = = n n York began the season with a 1 – 0 home win over the previous season &#39;s play @-@ off finalists , Northampton Town , with &lt;unk&gt; Jarvis scoring the winning goal in the 90th @-@ minute . However , defeat came in York &#39;s match against Championship side Burnley in the first round of the League Cup , going down 4 – 0 at home . The team endured their first league defeat of the season in the following game after being beaten 2 – 0 away by Dagenham &amp; Redbridge , the home team scoring in each half . York then held Hartlepool United to a 0 – 0 home draw , before being beaten 3 – 2 away by Bristol Rovers , in which Jarvis scored twice before John @-@ Joe O &#39;Toole scored the winning goal for the home team in the 67th @-@ minute . Two signings were made shortly before the transfer deadline ; defender George Taft was signed on a one @-@ month loan from Leicester City , while Middlesbrough midfielder Ryan Brobbel joined on a one @-@ month loan . &lt;unk&gt; John &lt;unk&gt; , who had been told he had no future with the club , departed after signing for FC Halifax Town . Jarvis gave York the lead away at Exeter City before Alan &lt;unk&gt; scored in each half to see the home team win 2 – 1 . n n = = = September = = = n n York suffered their first home league defeat of the season after AFC Wimbledon won 2 – 0 , with Michael Smith scoring in each half . Former Ipswich Town midfielder Josh Carson , who had a spell on loan with York the previous season , signed a contract until the end of 2013 – 14 and Sheffield United midfielder Elliott &lt;unk&gt; signed on a one @-@ month loan . Brobbel opened the scoring in the second minute of his home debut against Mansfield Town , although the away team went on to score twice to win 2 – 1 . York &#39;s run of four defeats ended following a 1 – 1 draw away to Wycombe Wanderers , in which McGurk gave York the lead before the home team levelled through Dean Morgan . Taft was sent back to Leicester after he fell behind McGurk , Parslow and Smith in the pecking order for a central defensive berth . York achieved their first win since the opening day of the season after beating Portsmouth 4 – 2 at home , with Fletcher ( 2 ) , Montrose and Jarvis scoring . n n = = = October = = = n n Defender Luke O &#39;Neill was signed from Burnley on a 28 @-@ day emergency loan . He made his debut in York &#39;s 3 – 0 win away at Torquay , which was the team &#39;s first successive win of the season . York were knocked out of the Football League Trophy in the second round after being beaten 3 – 0 at home by League One team Rotherham United , before their winning streak in the league was ended with a 3 – 0 defeat away to Newport County . York drew 2 – 2 away to Chesterfield , having taken a two @-@ goal lead through O &#39;Neill and Jarvis , before the home team fought back through Armand &lt;unk&gt; and Jay O &lt;unk&gt; . The team then hosted Fleetwood Town , and the visitors won 2 – 0 with goals scored in each half by Gareth Evans and &lt;unk&gt; Matt . Scunthorpe United were beaten 4 – 1 at home to end York &#39;s three @-@ match run without a win , with all the team &#39;s goals coming in the first half from Carson , Fletcher and Brobbel ( 2 ) . n n = = = November = = = n n Bowman scored his first goals for York away to Cheltenham Town , as York twice fought back from behind to draw 2 – 2 . York drew 3 – 3 away to Bristol Rovers to earn a first round replay in the FA Cup , taking the lead through Jarvis before Eliot Richards equalised for the home team . Carson scored a 30 yard volley to put York back in the lead , and after Bristol Rovers goals from Matt &lt;unk&gt; and Chris &lt;unk&gt; , Fletcher scored an 86th @-@ minute equaliser for York . Bowman scored with a header from an O &#39;Neill cross to open the scoring at home to Plymouth Argyle , which was the first goal the visitors had conceded in 500 minutes of action . However , Plymouth equalised 11 minutes later through &lt;unk&gt; &lt;unk&gt; and the match finished a 1 – 1 draw . York were knocked out of the FA Cup after losing 3 – 2 at home to Bristol Rovers in a first round replay ; the visitors were 3 – 0 up by 50 @-@ minutes before Fletcher pulled two back for York with a penalty and a long @-@ range strike . n Defender Keith Lowe , of Cheltenham , and goalkeeper Nick Pope , of Charlton Athletic , were signed on loan until January 2014 . They both played in York &#39;s first league defeat in four weeks , 2 – 1 away , to Southend United . &lt;unk&gt; &lt;unk&gt; gave Southend the lead early into the match and Bowman equalised for York with a low strike during the second half , before Luke Prosser scored the winning goal for the home side in stoppage time . With Pope preferred in goal , &lt;unk&gt; returned to Blackpool on his own accord , although his loan agreement would stay in place until January 2014 . York then drew 0 – 0 away to Morecambe . After Pope was recalled from his loan by Charlton , York signed Wolverhampton Wanderers goalkeeper Aaron McCarey on loan until January 2014 . McCarey kept a clean sheet in York &#39;s 0 – 0 home draw with Rochdale . n n = = = December = = = n n Cresswell retired from playing as a result of an eye complaint and a knee injury . York drew 1 – 1 away to Burton Albion , with an own goal scored by Shane &lt;unk&gt; @-@ &lt;unk&gt; giving York the lead in the 64th @-@ minute before the home team equalised eight minutes later through Billy &lt;unk&gt; . Atkinson was released after failing to force himself into the first team and signed for Scarborough Athletic , with whom he had been on loan . York drew 0 – 0 at home with second @-@ placed Oxford United , in which Carson came closest to scoring with a volley that &lt;unk&gt; across the face of the goal . This was followed by another draw after the match away to Accrington Stanley finished 1 – 1 , with the home team &lt;unk&gt; 10 minutes after a Fletcher penalty had given York the lead in the 35th @-@ minute . Striker &lt;unk&gt; McDonald , who had been released by Peterborough United , was signed on a contract until the end of the season . York &#39;s last match of 2013 was a 2 – 1 defeat away at Bury , a result that ended York &#39;s run of consecutive draws at five . The home team were 2 – 0 up by the 19th @-@ minute , before Michael Coulson scored York &#39;s goal in the 73rd @-@ minute . This result meant York would begin 2014 in 22nd @-@ position in the table , only out of the relegation zone on goal difference . n n = = = January = = = n n Jarvis scored the only goal in York &#39;s first win since October 2013 , a 1 – 0 home victory over Morecambe on New Year &#39;s Day . McCarey was recalled by Wolverhampton Wanderers due to an injury to one of their &lt;unk&gt; , while O &#39;Neill was recalled by Burnley to take part in their FA Cup match . York achieved back @-@ to @-@ back wins for the first time since October 2013 after Dagenham &amp; Redbridge were beaten 3 – 1 at home , with Bowman opening the scoring in the second half before Fletcher scored twice . Adam Reed , who had a spell on loan with York in the previous season , was signed on a contract until the end of the season after parting company with Burton . Davies &#39; loan was extended , while Brobbel and &lt;unk&gt; returned to their parent clubs . Cheltenham club captain Russell Penn , a midfielder , was signed on a two @-@ and @-@ a @-@ half @-@ year contract for an undisclosed fee . Lowe was subsequently signed permanently from Cheltenham on a two @-@ and @-@ a @-@ half @-@ year contract for an undisclosed fee . Having been allowed to leave the club on a free transfer , Ashley Chambers signed for Conference Premier club Cambridge United . n York achieved three successive wins for the first time in 2013 – 14 after beating Northampton 2 – 0 away , with Bowman and Fletcher scoring in three @-@ second half minutes . Defender John McCombe was signed on a two @-@ and @-@ a @-@ half @-@ year contract following his release from Mansfield , before Clay and Jamal &lt;unk&gt; left York by mutual consent . Pope returned to York on loan from Charlton for the remainder of the season . York &#39;s run of wins ended with a 0 – 0 draw at home to Bristol Rovers , before their first defeat of the year came after losing 2 – 0 away to Hartlepool . Preston winger Will Hayhurst , a Republic of Ireland under @-@ 21 international , was signed on a one @-@ month loan . York fell to a successive defeat for the first time since September 2013 after being beaten 2 – 0 at home by Chesterfield . Shortly after the match , Smith left the club by mutual consent to pursue first @-@ team football . n n = = = February = = = n n Fletcher scored a 90th @-@ minute winner for York away to Fleetwood in a 2 – 1 win , a result that ended Fleetwood &#39;s five @-@ match unbeaten run . York then drew 0 – 0 at home to fellow mid @-@ table team Cheltenham , before beating Plymouth 4 – 0 away with goals from Fletcher , McCombe ( 2 ) and Carson as the team achieved successive away wins for the first time in 2013 – 14 . York went without scoring for a fourth consecutive home match after drawing 0 – 0 with Southend . Having worn the &lt;unk&gt; since an injury to McGurk , Penn was appointed captain for the rest of the season , a position that had earlier been held by Smith and Parslow . n n = = = March = = = n n York achieved their first home win in five matches after beating Exeter 2 – 1 , with first half goals scored by McCombe and Coulson . Hayhurst &#39;s loan was extended to the end of the season , having impressed in his six appearances for the club . Coulson scored again with the only goal , a 41st @-@ minute header , in York &#39;s 1 – 0 away win over AFC Wimbledon . Bowman scored the only goal with a 32nd @-@ minute penalty as York won 1 – 0 away against Mansfield , in which Fletcher missed the opportunity to extend the lead when his stoppage time penalty was saved by Alan Marriott . York moved one place outside the play @-@ offs with a 2 – 0 home win over Wycombe , courtesy of a second Bowman penalty in as many matches and a Carson goal from the edge of the penalty area . Coulson scored York &#39;s only goal in a 1 – 0 away win over struggling Portsmouth with a low volley in the fifth @-@ minute ; this result meant York moved into the play @-@ offs in seventh @-@ place with eight fixtures remaining . n Striker Calvin Andrew , who had been released by Mansfield in January 2014 , was signed on a contract for the remainder of the season . He made his debut as a substitute in York &#39;s 1 – 0 home win over bottom of the table Torquay , in which Hayhurst scored the only goal in the 11th @-@ minute with an 18 yard shot that &lt;unk&gt; off Aaron &lt;unk&gt; . Middlesbrough winger Brobbel rejoined on loan until the end of the season , following an injury to Carson . York &#39;s run of successive wins ended on six matches after a 0 – 0 home draw with Burton , and this result saw York drop out of the play @-@ offs in eighth @-@ place . With the team recording six wins and one draw in March 2014 , including six clean sheets , Worthington was named League Two Manager of the Month . n n = = = April = = = n n Pope made a number of saves as York held league leaders Rochdale to a 0 – 0 away draw , with a point being enough to lift the team back into seventh @-@ place . York were prevented from equalling a club record of eight consecutive clean sheets when Accrington scored a stoppage time equaliser in a 1 – 1 home draw , in which York had taken earlier taken the lead with a Coulson penalty . A 1 – 0 win away win over Oxford , which was decided by a second half Coulson penalty , resulted in York moving one place above their opponents and back into seventh @-@ place . York consolidated their place in a play @-@ off position after beating Bury 1 – 0 at home with a fifth @-@ minute goal scored by Lowe from a Hayhurst corner . The result meant York opened up a five @-@ point lead over eighth @-@ placed Oxford with two fixtures remaining . A place in the League Two play @-@ offs was secured following a 1 – 0 win over Newport at home , in which Coulson scored the only goal in the 77th @-@ minute with a 25 yard free kick . Pope earned a nomination for League Two Player of the Month for April 2014 , having conceded only one goal in five matches in that period . n n = = = May = = = n n The league season concluded with an away match against divisional runners @-@ up Scunthorpe ; having gone two goals down York fought back to draw 2 – 2 with goals scored by Brobbel and Andrew . This result meant York finished the season in seventh @-@ place in League Two , and would thus play fourth @-@ placed Fleetwood in the play @-@ off semi @-@ final on the back of a 17 @-@ match unbeaten run . York lost 1 – 0 to Fleetwood in the first leg at &lt;unk&gt; Crescent ; the goal came from former York player &lt;unk&gt; Blair in the 50th @-@ minute , who scored from close range after Antoni &lt;unk&gt; &#39;s shot was blocked on the line . A 0 – 0 draw away to Fleetwood in the second leg meant York were eliminated 1 – 0 on aggregate , ending the prospect of a second promotion in three seasons . At an awards night held at York Racecourse , Oyebanjo was voted &lt;unk&gt; of the Year for 2013 – 14 . n n = = Summary and aftermath = = n n York mostly occupied the bottom half of the table before the turn of the year , and dropped as low as 23rd in September 2013 . During February 2014 the team broke into the top half of the table and with one match left were in sixth @-@ place . York &#39;s defensive record was the third best in League Two with 41 goals conceded , bettered only by Southend ( 39 ) and Chesterfield ( 40 ) . Davies made the highest number of appearances over the season , appearing in 47 of York &#39;s 52 matches . Fletcher was York &#39;s top scorer in the league and in all competitions , with 10 league goals and 13 in total . He was the only player to reach double figures , and was followed by Jarvis with nine goals . n After the season ended York released Tom Allan , Andrew , Dickinson , McDonald , Puri and Reed , while McGurk retired from professional football . Bowman and Oyebanjo left to sign for Torquay and Crawley Town respectively while Coulson signed a new contract with the club . York &#39;s summer signings included goalkeeper Jason &lt;unk&gt; from Tranmere Rovers , defenders &lt;unk&gt; &lt;unk&gt; from Dagenham , Marvin McCoy from Wycombe and Dave Winfield from Shrewsbury Town , midfielders &lt;unk&gt; &lt;unk&gt; from Mansfield , Anthony &lt;unk&gt; from Southend and Luke &lt;unk&gt; from Shrewsbury and striker Jake Hyde from &lt;unk&gt; . n n = = Match details = = n n League positions are sourced by &lt;unk&gt; , while the remaining information is referenced individually . n n = = = Football League Two = = = n n n = = = League table ( part ) = = = n n n = = = FA Cup = = = n n n = = = League Cup = = = n n n = = = Football League Trophy = = = n n n = = = Football League Two play @-@ offs = = = n n n = = &lt;unk&gt; = = n n n = = = In = = = n n &lt;unk&gt; around club names denote the player &#39;s contract with that club had expired before he joined York . n n = = = Out = = = n n &lt;unk&gt; around club names denote the player joined that club after his York contract expired . n n = = = Loan in = = = n n n = = = Loan out = = = n n n = = Appearances and goals = = n n Source : n Numbers in parentheses denote appearances as substitute . n Players with names struck through and marked left the club during the playing season . n Players with names in italics and marked * were on loan from another club for the whole of their season with York . n Players listed with no appearances have been in the &lt;unk&gt; squad but only as unused &lt;unk&gt; . n Key to positions : &lt;unk&gt; – &lt;unk&gt; ; &lt;unk&gt; – Defender ; &lt;unk&gt; – &lt;unk&gt; ; &lt;unk&gt; – Forward n n . 0 n = Big Boy ( song ) = n n &quot; Big Boy &quot; &lt;unk&gt; &quot; I &#39;m A Big Boy Now &quot; was the first single ever recorded by the Jackson 5 , which was released by Steeltown Records in January 1968 . The group played instruments on many of their Steeltown compositions , including &quot; Big Boy &quot; . The song was neither a critical nor commercial success , but the Jackson family were delighted with the outcome nonetheless . n The Jackson 5 would release a second single with Steeltown Records before moving to Motown Records . The group &#39;s recordings at Steeltown Records were thought to be lost , but they were re... | . 1 n = The Remix ( Lady Gaga album ) = n n The Remix is a remix album by American recording artist Lady Gaga . Released in Japan on March 3 , 2010 , it contains remixes of the songs from her first studio album , The Fame ( 2008 ) , and her third extended play , The Fame Monster ( 2009 ) . A revised version of the track list was prepared for release in additional markets , beginning with Mexico on May 3 , 2010 . A number of recording artists have produced the songs , including Pet Shop Boys , Passion Pit and The Sound of Arrows . The remixed versions feature both uptempo and &lt;unk&gt; composit... | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; df_train = pd.read_csv(path/&#39;train.csv&#39;,header=None) df_train.head(2) . 0 . 0 n = 2013 – 14 York City F.C. season = n n The 2013 – 14 season was the &lt;unk&gt; season of competitive association football and 77th season in the Football League played by York City Football Club , a professional football club based in York , North Yorkshire , England . Their 17th @-@ place finish in 2012 – 13 meant it was their second consecutive season in League Two . The season ran from 1 July 2013 to 30 June 2014 . n Nigel Worthington , starting his first full season as York manager , made eight permanent summer signings . By the turn of the year York were only above the relegation z... | . 1 n = Big Boy ( song ) = n n &quot; Big Boy &quot; &lt;unk&gt; &quot; I &#39;m A Big Boy Now &quot; was the first single ever recorded by the Jackson 5 , which was released by Steeltown Records in January 1968 . The group played instruments on many of their Steeltown compositions , including &quot; Big Boy &quot; . The song was neither a critical nor commercial success , but the Jackson family were delighted with the outcome nonetheless . n The Jackson 5 would release a second single with Steeltown Records before moving to Motown Records . The group &#39;s recordings at Steeltown Records were thought to be lost , but they were re... | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; df_test = pd.read_csv(path/&#39;test.csv&#39;,header=None) df_test.head(2) . 0 . 0 n = Tropical Storm &lt;unk&gt; ( 2008 ) = n n Tropical Storm &lt;unk&gt; was the tenth tropical storm of the 2008 Atlantic hurricane season . &lt;unk&gt; developed out of a strong tropical wave which moved off the African coast on August 31 . The wave quickly became organized and was declared Tropical Depression Ten while located 170 mi ( 270 km ) to the south @-@ southeast of the Cape Verde Islands on September 2 . The depression was quickly upgraded to Tropical Storm &lt;unk&gt; around noon the same day . Over the next several days , &lt;unk&gt; moved in a general west @-@ northwest direction and reached its peak... | . 1 n = Calvin &lt;unk&gt; = n n Calvin &lt;unk&gt; ( born November 2 , 1984 ) is a Canadian football running back for the Edmonton &lt;unk&gt; of the Canadian Football League ( &lt;unk&gt; ) . He played as a &lt;unk&gt; until 2014 , when he became the starting fullback for the &lt;unk&gt; . &lt;unk&gt; is known for being able to fill many roles at his position , with &lt;unk&gt; &lt;unk&gt; Chris Schultz noting in 2010 that he is a &quot; multi @-@ purpose running back who catches the ball extremely well , blocks well and runs well &quot; . He is a champion of the &lt;unk&gt; Grey Cup . n Prior to being drafted by the Edmonton &lt;unk&gt; in the fourth round of ... | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; df_combined = pd.concat([df_train,df_test]) df_combined.head(2) . 0 . 0 n = 2013 – 14 York City F.C. season = n n The 2013 – 14 season was the &lt;unk&gt; season of competitive association football and 77th season in the Football League played by York City Football Club , a professional football club based in York , North Yorkshire , England . Their 17th @-@ place finish in 2012 – 13 meant it was their second consecutive season in League Two . The season ran from 1 July 2013 to 30 June 2014 . n Nigel Worthington , starting his first full season as York manager , made eight permanent summer signings . By the turn of the year York were only above the relegation z... | . 1 n = Big Boy ( song ) = n n &quot; Big Boy &quot; &lt;unk&gt; &quot; I &#39;m A Big Boy Now &quot; was the first single ever recorded by the Jackson 5 , which was released by Steeltown Records in January 1968 . The group played instruments on many of their Steeltown compositions , including &quot; Big Boy &quot; . The song was neither a critical nor commercial success , but the Jackson family were delighted with the outcome nonetheless . n The Jackson 5 would release a second single with Steeltown Records before moving to Motown Records . The group &#39;s recordings at Steeltown Records were thought to be lost , but they were re... | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; print(&quot;df_train: &quot;,df_train.shape) print(&quot;df_test: &quot;,df_test.shape) print(&quot;df_combined: &quot;,df_combined.shape) . df_train: (615, 1) df_test: (47, 1) df_combined: (662, 1) . # df[df.columns[2]] df_tok, count = tokenize_df(df_combined,[df_combined.columns[0]]) . df_tok.head(3) . text text_length . 0 [xxbos, =, 2013, –, 14, xxmaj, york, xxmaj, city, xxup, f.c, ., season, =, n▁ n▁, xxmaj, the, 2013, –, 14, season, was, the, xxunk, season, of, competitive, association, football, and, 77th, season, in, the, xxmaj, football, xxmaj, league, played, by, xxmaj, york, xxmaj, city, xxmaj, football, xxmaj, club, ,, a, professional, football, club, based, in, xxmaj, york, ,, xxmaj, north, xxmaj, yorkshire, ,, xxmaj, england, ., xxmaj, their, 17th, -, place, finish, in, 2012, –, 13, meant, it, was, their, second, consecutive, season, in, xxmaj, league, xxmaj, two, ., xxmaj, the, season, ran, from... | 4405 | . 1 [xxbos, =, xxmaj, big, xxmaj, boy, (, song, ), =, n▁ n▁, &quot;, xxmaj, big, xxmaj, boy, &quot;, xxunk, &quot;, i, &#39;, m, a, xxmaj, big, xxmaj, boy, xxmaj, now, &quot;, was, the, first, single, ever, recorded, by, the, xxmaj, jackson, 5, ,, which, was, released, by, xxmaj, steeltown, xxmaj, records, in, xxmaj, january, 1968, ., xxmaj, the, group, played, instruments, on, many, of, their, xxmaj, steeltown, compositions, ,, including, &quot;, xxmaj, big, xxmaj, boy, &quot;, ., xxmaj, the, song, was, neither, a, critical, nor, commercial, success, ,, but, the, xxmaj, jackson, family, were, delighted, with, the, outcome, n... | 976 | . 2 [xxbos, =, xxmaj, the, xxmaj, remix, (, xxmaj, lady, xxmaj, gaga, album, ), =, n▁ n▁, xxmaj, the, xxmaj, remix, is, a, remix, album, by, xxmaj, american, recording, artist, xxmaj, lady, xxmaj, gaga, ., xxmaj, released, in, xxmaj, japan, on, xxmaj, march, 3, ,, 2010, ,, it, contains, remixes, of, the, songs, from, her, first, studio, album, ,, xxmaj, the, xxmaj, fame, (, 2008, ), ,, and, her, third, extended, play, ,, xxmaj, the, xxmaj, fame, xxmaj, monster, (, 2009, ), ., a, revised, version, of, the, track, list, was, prepared, for, release, in, additional, markets, ,, beginning, with, x... | 2251 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; # word and a rare word print(&quot;very common word (count[&#39;the&#39;]):&quot;, count[&#39;the&#39;]) print(&quot;moderately common word (count[&#39;prepared&#39;]):&quot;, count[&#39;prepared&#39;]) print(&quot;rare word (count[&#39;gaga&#39;]):&quot;, count[&#39;gaga&#39;]) . very common word (count[&#39;the&#39;]): 145485 moderately common word (count[&#39;prepared&#39;]): 113 rare word (count[&#39;gaga&#39;]): 20 . ??tokenize_df . doc(tokenize_df) . tokenize_df[source] . tokenize_df(df, text_cols, n_workers=2, rules=None, mark_fields=None, tok=None, tok_text_col=&#39;text&#39;) . Tokenize texts in df[text_cols] in parallel using n_workers and stores them in df[tok_text_col] . Type Default . df | | | . text_cols | | | . n_workers | int | 2 | . rules | NoneType | `` | . mark_fields | NoneType | `` | . tok | NoneType | `` | . tok_text_col | str | text | . Show in docs .",
            "url": "https://leungadh.github.io/coding/fastai/cookbook/2022/03/29/_03_23-CB-examining_text_datasets.html",
            "relUrl": "/fastai/cookbook/2022/03/29/_03_23-CB-examining_text_datasets.html",
            "date": " • Mar 29, 2022"
        }
        
    
  
    
        ,"post9": {
            "title": "FastAI Cookbook Ch 2. Examining image datasets in fast.ai",
            "content": "!pip install -Uqq fastbook import fastbook from fastbook import * from fastai.vision.all import * . |████████████████████████████████| 720 kB 5.0 MB/s |████████████████████████████████| 189 kB 48.3 MB/s |████████████████████████████████| 1.2 MB 45.4 MB/s |████████████████████████████████| 48 kB 4.5 MB/s |████████████████████████████████| 55 kB 3.7 MB/s |████████████████████████████████| 51 kB 291 kB/s |████████████████████████████████| 561 kB 50.2 MB/s |████████████████████████████████| 130 kB 55.8 MB/s . fastbook.setup_book() . Mounted at /content/gdrive . path = untar_data(URLs.FLOWERS) . . 100.00% [345243648/345236087 00:07&lt;00:00] path.ls() . (#4) [Path(&#39;/root/.fastai/data/oxford-102-flowers/jpg&#39;),Path(&#39;/root/.fastai/data/oxford-102-flowers/test.txt&#39;),Path(&#39;/root/.fastai/data/oxford-102-flowers/valid.txt&#39;),Path(&#39;/root/.fastai/data/oxford-102-flowers/train.txt&#39;)] . df_valid = pd.read_csv(path/&#39;valid.txt&#39;, header=None) df_valid.head() . 0 . 0 jpg/image_04467.jpg 89 | . 1 jpg/image_07129.jpg 44 | . 2 jpg/image_05166.jpg 4 | . 3 jpg/image_07002.jpg 34 | . 4 jpg/image_02007.jpg 79 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; (path/&#39;jpg&#39;).ls() . (#8189) [Path(&#39;/root/.fastai/data/oxford-102-flowers/jpg/image_03828.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-102-flowers/jpg/image_07661.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-102-flowers/jpg/image_03860.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-102-flowers/jpg/image_02212.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-102-flowers/jpg/image_06350.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-102-flowers/jpg/image_05954.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-102-flowers/jpg/image_07130.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-102-flowers/jpg/image_05585.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-102-flowers/jpg/image_03449.jpg&#39;),Path(&#39;/root/.fastai/data/oxford-102-flowers/jpg/image_02132.jpg&#39;)...] . img_files = get_image_files(path) img = PILImage.create(img_files[100]) img . img.to_thumb(180) . path = untar_data(URLs.BIWI_HEAD_POSE) . . 100.00% [452321280/452316199 00:10&lt;00:00] path.ls() . (#50) [Path(&#39;/root/.fastai/data/biwi_head_pose/10.obj&#39;),Path(&#39;/root/.fastai/data/biwi_head_pose/08.obj&#39;),Path(&#39;/root/.fastai/data/biwi_head_pose/24&#39;),Path(&#39;/root/.fastai/data/biwi_head_pose/05.obj&#39;),Path(&#39;/root/.fastai/data/biwi_head_pose/13.obj&#39;),Path(&#39;/root/.fastai/data/biwi_head_pose/03&#39;),Path(&#39;/root/.fastai/data/biwi_head_pose/18&#39;),Path(&#39;/root/.fastai/data/biwi_head_pose/19&#39;),Path(&#39;/root/.fastai/data/biwi_head_pose/11&#39;),Path(&#39;/root/.fastai/data/biwi_head_pose/20.obj&#39;)...] . (path/&quot;05&quot;).ls() . (#1894) [Path(&#39;/root/.fastai/data/biwi_head_pose/05/frame_00181_pose.txt&#39;),Path(&#39;/root/.fastai/data/biwi_head_pose/05/frame_00007_rgb.jpg&#39;),Path(&#39;/root/.fastai/data/biwi_head_pose/05/frame_00721_rgb.jpg&#39;),Path(&#39;/root/.fastai/data/biwi_head_pose/05/frame_00514_pose.txt&#39;),Path(&#39;/root/.fastai/data/biwi_head_pose/05/frame_00751_rgb.jpg&#39;),Path(&#39;/root/.fastai/data/biwi_head_pose/05/frame_00246_rgb.jpg&#39;),Path(&#39;/root/.fastai/data/biwi_head_pose/05/frame_00580_rgb.jpg&#39;),Path(&#39;/root/.fastai/data/biwi_head_pose/05/frame_00890_pose.txt&#39;),Path(&#39;/root/.fastai/data/biwi_head_pose/05/frame_00193_pose.txt&#39;),Path(&#39;/root/.fastai/data/biwi_head_pose/05/frame_00242_pose.txt&#39;)...] . img_files = get_image_files(path/&#39;10&#39;) img = PILImage.create(img_files[8]) img.to_thumb(180) . path/&#39;05/frame_00191_pose.txt&#39; . Path(&#39;/root/.fastai/data/biwi_head_pose/05/frame_00191_pose.txt&#39;) . df_pose = pd.read_csv(path/&#39;05/frame_00191_pose.txt&#39;, header=None) df_pose.head() . 0 . 0 0.860993 0.162766 -0.481869 | . 1 0.00729371 0.943363 0.331682 | . 2 0.508564 -0.289091 0.811042 | . 3 116.403 12.1671 871.544 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt;",
            "url": "https://leungadh.github.io/coding/fastai/cookbook/image/2022/03/29/_03_23-CB-examining_image_datasets.html",
            "relUrl": "/fastai/cookbook/image/2022/03/29/_03_23-CB-examining_image_datasets.html",
            "date": " • Mar 29, 2022"
        }
        
    
  
    
        ,"post10": {
            "title": "FastAI Cookbook Ch2. Cleaning up datasets in fast.ai",
            "content": "!pip install -Uqq fastbook import fastbook from fastbook import * from fastai.text.all import * from fastai.vision.all import * from fastai.tabular.all import * . |████████████████████████████████| 720 kB 5.1 MB/s |████████████████████████████████| 1.2 MB 43.4 MB/s |████████████████████████████████| 189 kB 51.7 MB/s |████████████████████████████████| 48 kB 4.8 MB/s |████████████████████████████████| 55 kB 4.0 MB/s |████████████████████████████████| 561 kB 52.3 MB/s |████████████████████████████████| 51 kB 298 kB/s |████████████████████████████████| 130 kB 53.0 MB/s . fastbook.setup_book() . Mounted at /content/gdrive . path = untar_data(URLs.ADULT_SAMPLE) . . 100.69% [974848/968212 00:00&lt;00:00] df = pd.read_csv(path/&#39;adult.csv&#39;) df.isnull().sum() . age 0 workclass 0 fnlwgt 0 education 0 education-num 487 marital-status 0 occupation 512 relationship 0 race 0 sex 0 capital-gain 0 capital-loss 0 hours-per-week 0 native-country 0 salary 0 dtype: int64 . # define transforms to apply to the tabular dataset procs = [FillMissing,Categorify] # define the dependent variable (y value) dep_var = &#39;salary&#39; # define columns that are continuous / categorical cont,cat = cont_cat_split(df, 1, dep_var=dep_var) . df_no_missing = TabularPandas(df,procs, cat, cont,y_names = dep_var) . df_no_missing.show(3) . workclass education marital-status occupation relationship race sex native-country education-num_na age fnlwgt education-num capital-gain capital-loss hours-per-week salary . 0 Private | Assoc-acdm | Married-civ-spouse | #na# | Wife | White | Female | United-States | False | 49 | 101320 | 12.0 | 0 | 1902 | 40 | &gt;=50k | . 1 Private | Masters | Divorced | Exec-managerial | Not-in-family | White | Male | United-States | False | 44 | 236746 | 14.0 | 10520 | 0 | 45 | &gt;=50k | . 2 Private | HS-grad | Divorced | #na# | Unmarried | Black | Female | United-States | True | 38 | 96185 | 10.0 | 0 | 0 | 32 | &lt;50k | . df_no_missing.items.head(3) . age workclass fnlwgt education education-num marital-status occupation relationship race sex capital-gain capital-loss hours-per-week native-country salary education-num_na . 0 49 | 5 | 101320 | 8 | 12.0 | 3 | 0 | 6 | 5 | 1 | 0 | 1902 | 40 | 40 | 1 | 1 | . 1 44 | 5 | 236746 | 13 | 14.0 | 1 | 5 | 2 | 5 | 2 | 10520 | 0 | 45 | 40 | 1 | 1 | . 2 38 | 5 | 96185 | 12 | 10.0 | 1 | 0 | 5 | 3 | 1 | 0 | 0 | 32 | 40 | 0 | 2 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; df_no_missing.items.isnull().sum() . age 0 workclass 0 fnlwgt 0 education 0 education-num 0 marital-status 0 occupation 0 relationship 0 race 0 sex 0 capital-gain 0 capital-loss 0 hours-per-week 0 native-country 0 salary 0 education-num_na 0 dtype: int64 .",
            "url": "https://leungadh.github.io/coding/fastai/cookbook/cleaning/2022/03/29/_03_23-CB-cleaning_up_datasets.html",
            "relUrl": "/fastai/cookbook/cleaning/2022/03/29/_03_23-CB-cleaning_up_datasets.html",
            "date": " • Mar 29, 2022"
        }
        
    
  
    
        ,"post11": {
            "title": "Deep learning with fast.ai cookbook - MNIST "hello world" example",
            "content": "!pip install -Uqq fastbook import fastbook from fastbook import * from fastai.vision.all import * . |████████████████████████████████| 720 kB 5.3 MB/s |████████████████████████████████| 1.2 MB 36.5 MB/s |████████████████████████████████| 189 kB 47.9 MB/s |████████████████████████████████| 48 kB 4.9 MB/s |████████████████████████████████| 55 kB 3.5 MB/s |████████████████████████████████| 561 kB 44.7 MB/s |████████████████████████████████| 51 kB 291 kB/s |████████████████████████████████| 130 kB 46.3 MB/s . fastbook.setup_book() . Mounted at /content/gdrive . # if the dataset has not been copied there already path = untar_data(URLs.MNIST) . . 100.03% [15687680/15683414 00:00&lt;00:00] path.ls() . (#2) [Path(&#39;/root/.fastai/data/mnist_png/training&#39;),Path(&#39;/root/.fastai/data/mnist_png/testing&#39;)] . %%time # create an image dataloaders object using the path # note that because of the directory structure of the dataset # the train and valid sets have to be explicitly specified # details here: https://github.com/fastai/fastai/issues/1129 dls = ImageDataLoaders.from_folder(path, train=&#39;training&#39;, valid=&#39;testing&#39;) # create a learner object using the dataloaders that was just defined # architecture is resnet18; see https://pytorch.org/hub/pytorch_vision_resnet/ # loss function is selected for multi class classification # accuracy is the metric used to optimize learn = cnn_learner(dls, resnet18, pretrained=False, loss_func=LabelSmoothingCrossEntropy(), metrics=accuracy) # fit the model for one epoch using 1cycle policy # see https://docs.fast.ai/callback.schedule.html#Learner.fit_one_cycle learn.fit_one_cycle(1, 0.1) . epoch train_loss valid_loss accuracy time . 0 | 0.557135 | 0.525823 | 0.990400 | 02:00 | . CPU times: user 1min 22s, sys: 3.96 s, total: 1min 26s Wall time: 2min 19s . dls.train.show_batch(max_n=4, nrows=1) . dls.valid.show_batch(max_n=4, nrows=1) . img_files = get_image_files(path/&quot;testing&quot;) img = PILImage.create(img_files[7000]) img . interp = ClassificationInterpretation.from_learner(learn) interp.plot_top_losses(4, nrows=1) . learn.summary() . Sequential (Input shape: 64 x 3 x 28 x 28) ============================================================================ Layer (type) Output Shape Param # Trainable ============================================================================ 64 x 64 x 14 x 14 Conv2d 9408 True BatchNorm2d 128 True ReLU ____________________________________________________________________________ 64 x 64 x 7 x 7 MaxPool2d Conv2d 36864 True BatchNorm2d 128 True ReLU Conv2d 36864 True BatchNorm2d 128 True Conv2d 36864 True BatchNorm2d 128 True ReLU Conv2d 36864 True BatchNorm2d 128 True ____________________________________________________________________________ 64 x 128 x 4 x 4 Conv2d 73728 True BatchNorm2d 256 True ReLU Conv2d 147456 True BatchNorm2d 256 True Conv2d 8192 True BatchNorm2d 256 True Conv2d 147456 True BatchNorm2d 256 True ReLU Conv2d 147456 True BatchNorm2d 256 True ____________________________________________________________________________ 64 x 256 x 2 x 2 Conv2d 294912 True BatchNorm2d 512 True ReLU Conv2d 589824 True BatchNorm2d 512 True Conv2d 32768 True BatchNorm2d 512 True Conv2d 589824 True BatchNorm2d 512 True ReLU Conv2d 589824 True BatchNorm2d 512 True ____________________________________________________________________________ 64 x 512 x 1 x 1 Conv2d 1179648 True BatchNorm2d 1024 True ReLU Conv2d 2359296 True BatchNorm2d 1024 True Conv2d 131072 True BatchNorm2d 1024 True Conv2d 2359296 True BatchNorm2d 1024 True ReLU Conv2d 2359296 True BatchNorm2d 1024 True AdaptiveAvgPool2d AdaptiveMaxPool2d ____________________________________________________________________________ 64 x 1024 Flatten BatchNorm1d 2048 True Dropout ____________________________________________________________________________ 64 x 512 Linear 524288 True ReLU BatchNorm1d 1024 True Dropout ____________________________________________________________________________ 64 x 10 Linear 5120 True ____________________________________________________________________________ Total params: 11,708,992 Total trainable params: 11,708,992 Total non-trainable params: 0 Optimizer used: &lt;function Adam at 0x7f0e785fab00&gt; Loss function: LabelSmoothingCrossEntropy() Model unfrozen Callbacks: - TrainEvalCallback - Recorder - ProgressCallback . img = PILImage.create(img_files[0]) img . learn.predict(img) . (&#39;6&#39;, TensorBase(6), TensorBase([0.0107, 0.0093, 0.0098, 0.0088, 0.0116, 0.0074, 0.9145, 0.0091, 0.0094, 0.0094])) . img = PILImage.create(img_files[2030]) img . learn.predict(img) . (&#39;0&#39;, TensorBase(0), TensorBase([0.9077, 0.0100, 0.0113, 0.0104, 0.0109, 0.0092, 0.0092, 0.0092, 0.0086, 0.0134])) . img = PILImage.create(img_files[5800]) img . learn.predict(img) . (&#39;5&#39;, TensorBase(5), TensorBase([0.0094, 0.0095, 0.0090, 0.0089, 0.0097, 0.9215, 0.0103, 0.0082, 0.0063, 0.0071])) .",
            "url": "https://leungadh.github.io/coding/2022/03/23/mnist_hello_world.html",
            "relUrl": "/2022/03/23/mnist_hello_world.html",
            "date": " • Mar 23, 2022"
        }
        
    
  
    
        ,"post12": {
            "title": "Notebook to validate Gradient setup",
            "content": "import fastai fastai.__version__ . &#39;2.1.5&#39; . !nvidia-smi . Sat Jul 3 22:40:46 2021 +--+ | NVIDIA-SMI 450.36.06 Driver Version: 450.36.06 CUDA Version: 11.0 | |-+-+-+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | | | | MIG M. | |===============================+======================+======================| | 0 Quadro P4000 On | 00000000:00:05.0 Off | N/A | | 46% 41C P0 34W / 105W | 853MiB / 8119MiB | 35% Default | | | | N/A | +-+-+-+ +--+ | Processes: | | GPU GI CI PID Type Process name GPU Memory | | ID ID Usage | |=============================================================================| +--+ .",
            "url": "https://leungadh.github.io/coding/colab/setup/2022/03/22/validate-gradient-setup.html",
            "relUrl": "/colab/setup/2022/03/22/validate-gradient-setup.html",
            "date": " • Mar 22, 2022"
        }
        
    
  
    
        ,"post13": {
            "title": "Python Line Plot",
            "content": "Python Line Plot . %matplotlib inline import matplotlib.pyplot as plt import numpy as np . Line plots . Showing the line plot of X and Y value . x:The x-coordinate | y:The y-coordinate | . k = np.linspace(0,10) #np.linspace (start, finish) equally divine into 50 numbers(default) kk = np.sin(x) k, kk . (array([ 0. , 0.20408163, 0.40816327, 0.6122449 , 0.81632653, 1.02040816, 1.2244898 , 1.42857143, 1.63265306, 1.83673469, 2.04081633, 2.24489796, 2.44897959, 2.65306122, 2.85714286, 3.06122449, 3.26530612, 3.46938776, 3.67346939, 3.87755102, 4.08163265, 4.28571429, 4.48979592, 4.69387755, 4.89795918, 5.10204082, 5.30612245, 5.51020408, 5.71428571, 5.91836735, 6.12244898, 6.32653061, 6.53061224, 6.73469388, 6.93877551, 7.14285714, 7.34693878, 7.55102041, 7.75510204, 7.95918367, 8.16326531, 8.36734694, 8.57142857, 8.7755102 , 8.97959184, 9.18367347, 9.3877551 , 9.59183673, 9.79591837, 10. ]), array([ 0. , 0.39692415, 0.72863478, 0.94063279, 0.99808748, 0.89155923, 0.63855032, 0.2806294 , -0.12339814, -0.50715171, -0.80758169, -0.97532829, -0.9828312 , -0.82885774, -0.53870529, -0.16004509, 0.24491007, 0.6096272 , 0.8741843 , 0.99511539, 0.95255185, 0.75348673, 0.43062587, 0.0370144 , -0.36267843, -0.70278422, -0.92742455, -0.99969166, -0.90771225, -0.66659829, -0.31596412, 0.08658207, 0.47490306, 0.78519883, 0.96648865, 0.98898712, 0.8489978 , 0.56952055, 0.19647269, -0.20885508, -0.57986856, -0.85561127, -0.99077947, -0.9631654 , -0.77730599, -0.4637374 , -0.07397807, 0.32793565, 0.67597047, 0.91294525])) . x = np.linspace(0,20) y1 = np.sin(x) y2 = np.sin(x - np.pi) plt.figure() plt.plot(x,y1) plt.plot(x,y2) plt.figure; . Implementing plot with . Color | Linestyle | Linewidth | Marker, Marker size | Label | Legend | . x = np.linspace(0, 20) y1 = np.sin(x) y2 = np.sin(x - np.pi) plt.figure() plt.plot(x, y1, color=&#39;black&#39;, linestyle=&#39;-&#39;, linewidth=2, marker=&#39;s&#39;, markersize=6, label=&#39;y1&#39;) plt.plot(x, y2, color=&#39;red&#39;, linestyle=&#39;--&#39;, linewidth=2, marker=&#39;^&#39;, markersize=6, label=&#39;y2&#39;) plt.legend() ; . &#39;&#39; .",
            "url": "https://leungadh.github.io/coding/python/visual/2022/03/20/Python-Line.html",
            "relUrl": "/python/visual/2022/03/20/Python-Line.html",
            "date": " • Mar 20, 2022"
        }
        
    
  
    
        ,"post14": {
            "title": "My First Post",
            "content": "Here is the date . Date:March 8, 2022 . Third sub-title . Testing the 3rd-sub-title .",
            "url": "https://leungadh.github.io/coding/jupyter/2022/03/08/First-Post.html",
            "relUrl": "/jupyter/2022/03/08/First-Post.html",
            "date": " • Mar 8, 2022"
        }
        
    
  
    
        ,"post15": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://leungadh.github.io/coding/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post16": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://leungadh.github.io/coding/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://leungadh.github.io/coding/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://leungadh.github.io/coding/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}